{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Знакомство</h2>\n",
    "\n",
    "Меня зовут Клышинский Эдуард Станиславович. <br>\n",
    "В течение этого года мы будем заниматься изучением возможностей языка Питон, а также библиотек для него.<br>\n",
    "Со мной можно связаться по почте eklyshinsky@hse.ru<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Морфологический анализ</h2>\n",
    "\n",
    "На начальных этапах обработки текста проводится два этапа анализа: <b>графематический</b> (выделение предложений и слов) и <b>морфологический</b> (определение начальной формы слова, его части речи и грамматических параметров). Этап синтаксического анализа мы сейчас разбирать не будем, так как его информация требуется не всегда.<br>\n",
    "Задачей графематического анализа является разделение текста на составные части - врезки, абзацы, предложения, слова. В таких задачах как машинный перевод, точность данного этапа может существенно влиять на точность получаемых результатов. Например, точка, используемая для сокращений, может быть воспринята как конец предложения, что полность разорвет его семантику.<br>\n",
    "Задачей морфологического анализа является определение начальной формы слова, его части речи и грамматических параметров. В некоторых случаях от слова требуется только начальная форма, в других - только начальная форма и часть речи.<br>\n",
    "Существует два больших подхода к морфологическому анализу: <b>стемминг</b> и <b>поиск по словарю</b>. Для проведения стемминга оставляется справочник всех окончаний для данного языка. Для пришедшего слова проверяется его окончание и по нему делается прогноз начальной формы и части речи.<br>\n",
    "Например, мы создаем справочник, в котором записываем все окончания прилагательных: <i>-ому, -ему, -ой, -ая, -ий, -ый, ...</i> Теперь все слова, которые имеют такое окончание будут считаться прилагаельными: <i>синий, циклический, красного, больному</i>. Заодно прилагательными будут считаться причастия (<i>делающий, строившему</i>) и местоимения (<i>мой, твой, твоему</i>). Также не понятно что делать со словами, имеющими пустое окончание. Отдельную проблему составляют такие слова, как <i>стекло, больной, вина</i>, которые могут разбираться несколькими вариантами (это явление называется <b>омонимией</b>). Помимо этого, стеммер может просто откусывать окончания, оставляя лишь псевдооснову.<br>\n",
    "Большинство проблем здесь решается, но точность работы бессловарных стеммеров находится на уровне 80%. Чтобы повысить точность испольуют морфологический анализ со словарем. Разработчики составляют словарь слов, встретившихся в текстах (<a href=\"http://opencorpora.org/dict.php\">здесь</a> можно найти пример такого словаря). Теперь каждое слово будет искаться в словаре и не предсказываться, а выдаваться точно. Для слов, отсутствующих в словаре, может применяться предсказание, пообное работе стеммера.<br>\n",
    "Посмотрим как работает словарная морфология на примере системы <a href=\"https://pymorphy2.readthedocs.io/en/latest/\">pymorphy2</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2 # Импортируем морфологический анализатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,nomn'), normal_form='стекло', score=0.690476, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 0),))\n",
      "Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,accs'), normal_form='стекло', score=0.285714, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 3),))\n",
      "Parse(word='стекло', tag=OpencorporaTag('VERB,perf,intr neut,sing,past,indc'), normal_form='стечь', score=0.023809, methods_stack=((DictionaryAnalyzer(), 'стекло', 1015, 3),))\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer() # Создает объект морфоанализатора и загружет словарь.\n",
    "wordform = morph.parse('стекло')  # Проведем анализ слова \"стекло\".\n",
    "for w in wordform: # Возвращается список вариантов разбора.\n",
    "    print(w) # Посмотрим на полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "стекло\n",
      "стекло\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer() # Создает объект морфоанализатора и загружет словарь.\n",
    "wordform = morph.parse('стекло')  # Проведем анализ слова \"стекло\".\n",
    "for w in wordform: # Возвращается список вариантов разбора.\n",
    "    if 'NOUN' in w.tag: # Возьмем только варианты разбора как существительного.\n",
    "        print(w.normal_form)# Посмотрим на начальные формы в анализе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='делавшихся', tag=OpencorporaTag('PRTF,impf,intr,past,actv plur,gent'), normal_form='делаться', score=0.3333333333333333, methods_stack=((DictionaryAnalyzer(), 'делавшихся', 234, 61),)),\n",
       " Parse(word='делавшихся', tag=OpencorporaTag('PRTF,impf,intr,past,actv anim,plur,accs'), normal_form='делаться', score=0.3333333333333333, methods_stack=((DictionaryAnalyzer(), 'делавшихся', 234, 63),)),\n",
       " Parse(word='делавшихся', tag=OpencorporaTag('PRTF,impf,intr,past,actv plur,loct'), normal_form='делаться', score=0.3333333333333333, methods_stack=((DictionaryAnalyzer(), 'делавшихся', 234, 66),))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('делавшихся')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из вывода, слово \"стекло\" может быть неодушевленным существительным среднего рода, единственного числа, именительного падежа <i>tag=OpencorporaTag('NOUN,inan,neut sing,nomn')</i>, аналогично, но в винительном падеже (<i>'NOUN,inan,neut sing,accs'</i>), и глаголом <i>'VERB,perf,intr neut,sing,past,indc'</i>. При этом в первой форме оно встречается в 75% случаев (<i>score=0.75</i>), во второй в 18,75% случаев (<i>score=0.1875</i>), а как глагол - лишь в 6,25% (<i>score=0.0625</i>). Самым простым видом борьбы с омонимией является выбор нулевого элемента из списка, возвращенного морфологическим анализом. Такой подход дает около 90% точности при выборе начальной формы и до 80% если мы обращаем внимание на грамматические параметры.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо Pymorphy можно использовать PyMystem. Его плюсом является тот факт, что он сам проводит графематический анализ и снимает омонимию. Используя функцию lemmatize можно получить набор начальных форм слов. Используя функцию analyze можно получить полную информацию о словах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `lemmatize` делит текст на слова и знаки препинания, а затем возвращает для них только начальную форму.\n",
    "\n",
    "Функция `analyze` возвращает не только начальную форму, но и всю информацию о слове, как это делал перед этим Pymorphy. \n",
    "\n",
    "Основным отличием является то, что Mystem снимает омонимию. Как видно из примера, делает он это не всегда корректно, но нам не придется думать о том, какое вариант разбора следует взять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['этот', ' ', 'тип', ' ', 'становиться', ' ', 'есть', ' ', 'в', ' ', 'цех', '\\n']\n",
      "-----\n",
      "{'analysis': [{'lex': 'этот', 'wt': 1, 'gr': 'APRO=(им,мн|вин,мн,неод)'}], 'text': 'эти'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'тип', 'wt': 0.8700298642, 'gr': 'S,муж,неод=(вин,мн|им,мн)'}], 'text': 'типы'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'становиться', 'wt': 0.9821285244, 'gr': 'V,нп=прош,мн,изъяв,сов'}], 'text': 'стали'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'есть', 'wt': 0.0492236161, 'gr': 'V,несов,пе=инф'}], 'text': 'есть'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'цех', 'wt': 1, 'gr': 'S,муж,неод=(дат,ед|местн,ед)'}], 'text': 'цеху'}\n",
      "{'text': '\\n'}\n"
     ]
    }
   ],
   "source": [
    "phrase = 'эти типы стали есть в цеху'\n",
    "mystem = pymystem3.Mystem()\n",
    "print(mystem.lemmatize(phrase)) # lemmatize возвращает только начальные формы.\n",
    "print('-----')\n",
    "for word in mystem.analyze(phrase): # analyze возвращает полный разбор.\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'система', 'wt': 1, 'gr': 'S,жен,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'Системы'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'автоматизированный', 'wt': 0.6585352169, 'gr': 'A,полн=(вин,ед,муж,од|род,ед,муж|род,ед,сред)'}], 'text': 'автоматизированного'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'проектирование', 'wt': 1, 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'проектирования'}\n",
      "{'text': '\\n'}\n",
      "-----\n",
      "{'analysis': [{'lex': 'система', 'wt': 1, 'gr': 'S,жен,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'Системы'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сделать', 'wt': 1, 'gr': 'V,сов,пе=(прош,вин,ед,прич,полн,муж,страд,од|прош,род,ед,прич,полн,муж,страд|прош,род,ед,прич,полн,сред,страд)'}], 'text': 'сделанного'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'проектирование', 'wt': 1, 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'проектирования'}\n",
      "{'text': '\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на варианты разбора фраз\n",
    "phrase = 'Системы автоматизированного проектирования' # ... и обнаружим ошибку.\n",
    "for word in mystem.analyze(phrase): \n",
    "    print(word)\n",
    "print('-----')\n",
    "phrase = 'Системы сделанного проектирования' \n",
    "for word in mystem.analyze(phrase): \n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одна библиотека - NLTK. По сравнению с двумя предыдущими библиотеками она обладает более широкой функциональностью и изначально писалась для работы с разными языками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # Иностранный морфологический анализатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед началом использования необходимо загрузить необходимые библиотеки или корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download() # По дороге будут появляться поле ввода. Грузит всё из Сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edward/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/edward/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]     /home/edward/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/edward/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # Сразу грузит что попросили.\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_ru')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `word_tokenize` возвращает начальные формы слов. \n",
    "\n",
    "Функция `pos_tag` возвращает список начальных форм и их частей речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Эти', 'типы', 'стали', 'есть', 'в', 'цеху'],\n",
       " [('Эти', 'типы'),\n",
       "  ('типы', 'стали'),\n",
       "  ('стали', 'есть'),\n",
       "  ('есть', 'в'),\n",
       "  ('в', 'цеху')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация. Надо не забыть сказать, что анализируем русский язык.\n",
    "tokens = nltk.word_tokenize('Эти типы стали есть в цеху', language='russian') \n",
    "bi_tokens = list(nltk.bigrams(tokens))\n",
    "tokens, bi_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Эти', 'A-PRO=pl'),\n",
       "  ('типы', 'S'),\n",
       "  ('стали', 'V'),\n",
       "  ('есть', 'V'),\n",
       "  ('в', 'PR'),\n",
       "  ('цеху', 'S')],\n",
       " [(('Эти', 'A-PRO=pl'), ('типы', 'S')),\n",
       "  (('типы', 'S'), ('стали', 'V')),\n",
       "  (('стали', 'V'), ('есть', 'V')),\n",
       "  (('есть', 'V'), ('в', 'PR')),\n",
       "  (('в', 'PR'), ('цеху', 'S'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = nltk.pos_tag(tokens, lang='rus') # Частеречная разметка.\n",
    "bi_pos = list(nltk.bigrams(pos))\n",
    "pos, bi_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У NLTK заведен список стоп-слов, которые лучше фильтровать при анализе текстов. Но их не очень много. Зато самые мешающиеся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего русских стоп-слов 151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Эти', 'типы', 'стали', 'цеху']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оставим только те слова, которых нет в списке стоп-слов.\n",
    "filtered_words = [token for token in tokens \n",
    "                  if token not in nltk.corpus.stopwords.words('russian')]\n",
    "print('всего русских стоп-слов', len(nltk.corpus.stopwords.words('russian')))\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведены примеры функций морфологического анализа текста для разных библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Подгружаем библиотеку с регулярными выражениями.\n",
    "\n",
    "# Для определения типов параметров функций нам потребуется простой питоновский ...\n",
    "from typing import Optional\n",
    "from pymorphy2.analyzer import MorphAnalyzer\n",
    "from pymystem3.mystem import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['милый_ADJF', 'мама_NOUN', 'мыло_NOUN', 'белый_ADJF', 'рама_NOUN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pymorphy\n",
    "def normalizePymorphy(morph: MorphAnalyzer, text: str) -> list:\n",
    "    tokens = re.findall('[A-Za-zА-Яа-яЁё]+\\-[A-Za-zА-Яа-яЁё]+|[A-Za-zА-Яа-яЁё]+', text)\n",
    "    words = []\n",
    "    for t in tokens:\n",
    "        pv = morph.parse(t)\n",
    "        words.append(f'{pv[0].normal_form}_{str(pv[0].tag.POS)}') # Берем наиболее вероятную форму.\n",
    "    return words    \n",
    "        \n",
    "# Обратите внимание, что про иностранные слова словарь ничего не знает.\n",
    "normalizePymorphy(morph, 'Милая мама мыла белую раму.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['милый_A', 'мама_S', 'мыло_S', 'белый_A', 'рама_S']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyMystem\n",
    "def normalizePymystem(mystem: Mystem, text: str) -> list:\n",
    "    tokens = mystem.analyze(text)\n",
    "    words = []\n",
    "    for t in tokens:\n",
    "        if 'analysis' in t.keys():\n",
    "            if t['analysis'] != []:\n",
    "                words.append(f\"{t['analysis'][0]['lex']}_{t['analysis'][0]['gr'][0]}\")\n",
    "            else:\n",
    "                words.append(f\"{t['text']}_U\")\n",
    "    return words    \n",
    "        \n",
    "# Не все считают, что причастие всегда выступает в роли глагола, но иногда так значительно проще.\n",
    "normalizePymystem(mystem, \"Милая мама мыла белую раму.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Милая_A=f', 'мама_S', 'мыла_V', 'белую_A=f', 'раму_S', '._NONLEX']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK\n",
    "def normalizeNLTK(text):\n",
    "    tokens = nltk.pos_tag(nltk.word_tokenize(text), lang='rus')\n",
    "    words = []\n",
    "    for t in tokens:\n",
    "        if t[0] != t[1]:\n",
    "            words.append(f'{t[0]}_{t[1]}')\n",
    "    return words    \n",
    "        \n",
    "# А вот здесь с частеречной разметкой всё плохо, а параметров нет вовсе.\n",
    "normalizeNLTK(\"Милая мама мыла белую раму.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но мы будем использовать pymorphy, так как он немного пошустрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим с какой скоростью работают эти анализаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/war_and_peace.txt') as fil:\n",
    "    textWP = fil.read()\n",
    "# Выделяем все слова написанные русской кириллицей.\n",
    "words = [w[0] for w in re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textWP)]\n",
    "newtext = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n            Лев Николаевич Толстой. Война и мир. Том 1\\n\\n             * ЧАСТЬ ПЕРВАЯ. * \\n\\n\\n          \\n          \\n\\n            I.\\n\\n\\n          \\n               -- Еh bien, mon prince. Gênes et Lucques ne sont plus que des apanages,\\n          des поместья, de la famille Buonaparte.  Non, je  vous préviens, que si vous\\n          ne  me dites pas, que nous avons la guerre, si vous vous permettez encore de\\n          pallier  toutes les infamies, toutes les  atrocités  de cet  Antichrist  (ma\\n          parole, j'y  crois) -- je  ne  vous  connais plus, vous n'êtes plus mon ami,\\n          vous n'êtes  plus  мой  верный  раб,  comme  vous  dites.  [1]  Ну,\\n          здравствуйте, здравствуйте.  Je vois  que  je  vous fais  peur, [2]\\n          садитесь и рассказывайте.\\n               Так говорила в и\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textWP[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Лев', ''),\n",
       " ('Николаевич', ''),\n",
       " ('Толстой', ''),\n",
       " ('Война', ''),\n",
       " ('и', ''),\n",
       " ('мир', ''),\n",
       " ('Том', ''),\n",
       " ('ЧАСТЬ', ''),\n",
       " ('ПЕРВАЯ', ''),\n",
       " ('Е', '')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textWP)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445508\n"
     ]
    }
   ],
   "source": [
    "print(len(words)) # Вся \"Война и мир\" занимает примерно 450 000 слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.29 s, sys: 0 ns, total: 6.29 s\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iniMorphy = []\n",
    "for w in words:\n",
    "    r = morph.parse(w)\n",
    "    iniMorphy.append(r[0].normal_form) # Берем только начальные формы слов, остальное нам не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Может быть это всё долгая работа списка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.01 s, sys: 0 ns, total: 6.01 s\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iniMorphy = []\n",
    "for w in words:\n",
    "    r = morph.parse(w)\n",
    "#     iniMorphy.append(r[0].normal_form) # Берем только начальные формы слов, остальное нам не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на скорость работы PyMyStem.\n",
    "\n",
    "!!! Внимание, высокое потребление памяти!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 14 s, total: 2min 43s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iniStem = mystem.lemmatize(newtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "iniStem = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 11.2 s, total: 1min 40s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iniStem = mystem.analyze(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Борьба за производительность</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примерно 50 000 слов в секунду для PyMorphy и 25 000 (со снятием омонимии) для MyStem.<br>\n",
    "Хорошо, но хочется быстрее.<br>\n",
    "Давайте посмотрим на статистику встречаемости слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter # Импортируем счетчик из стандартных библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и : 20324\n",
      "в : 10202\n",
      "не : 8434\n",
      "что : 7298\n",
      "на : 6441\n",
      "он : 5986\n",
      "с : 5748\n",
      "его : 3864\n",
      "как : 3681\n",
      "к : 3408\n"
     ]
    }
   ],
   "source": [
    "frqs = Counter(words) # Считаем сколько раз встречается каждое слово, ...\n",
    "frqsSorted = sorted(frqs.items(), key=lambda x: x[1], reverse=True) # ... сортируем, ...\n",
    "for x in frqsSorted[:10]: # ... и выводим 10 самых частоных слов.\n",
    "    print(f'{x[0]} : {frqs[x[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16921357192238973\n",
      "0.3676791438088654\n"
     ]
    }
   ],
   "source": [
    "print(sum([x[1] for x in frqsSorted[:10]]) / len(words))\n",
    "print(sum([x[1] for x in frqsSorted[:100]]) / len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сто самых частотных словоформ занимает примерно треть текста!<br>\n",
    "Возможно, если мы сумеем кешировать результаты работы морфологического анализатора, он начнет работать быстрее. Используем для этого обычный питоновский словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 718 ms, sys: 3.58 ms, total: 722 ms\n",
      "Wall time: 728 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iniMorphy2 = []\n",
    "cash = {} # Словарь для кеширования.\n",
    "for w in words:\n",
    "    if w in cash.keys(): # Если слово было закешировано, возьмем его из словаря.\n",
    "        iniMorphy2.append(cash[w])\n",
    "    else: # В противном случае проведем морфологический анализ.\n",
    "        r = morph.parse(w)\n",
    "        iniMorphy2.append(r[0].normal_form)\n",
    "        cash[w] = r[0].normal_form \n",
    "    # Вообще-то, можно было кешировать все результаты. Но нам же нужна только наиболее вероятная начальная форма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ускорение почти в 8 раз!<br>\n",
    "Имеет смысл сделать из этого какую-то удобную обертку, чтобы повторно использовать в своих дальнейших разработках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Создание и использование классов</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим свой собственный класс.<br>\n",
    "Класс - это тип, определенный пользователем (программистом). Класс содержит в себе как данные, так и функции, которые работают с этими данными.<br>\n",
    "Так как это тип, то можно создавать переменные этого типа. Каждая переменная будет хранить и обрабатывать свой набор данных.<br>\n",
    "В каждую функцию класса обязательно передается переменная, которая обычно называется self. Эта переменная содержит в себе объект, для которого производится вызов функции. Мы можем обращаться к свойствам данного объекта, используя или модифицируя тем самым этот объект."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ключевое слово class после которого идет название нашего класса.\n",
    "class FasterMorphology:\n",
    "    \"\"\"Class description.\"\"\"\n",
    "    __morpho: MorphAnalyzer\n",
    "    __cash: dict\n",
    "    \n",
    "    def __init__(self): # Функция инициализации объекта после его создания.\n",
    "        \"\"\"Initiolizes an object\"\"\"\n",
    "        # Создаем новую морфологию в каждом объекте. \n",
    "        # А вдруг мы будем потом работать с разными языками? У каждого объекта должна быть своя.\n",
    "        self.__morpho = pymorphy2.MorphAnalyzer() \n",
    "        self.__cash = {} # Создаем словарь для кеширования.\n",
    "        \n",
    "    def analyzeWords(self, words: list) -> list:\n",
    "        \"\"\" Multiline comment after a function will be placed into its documentation.\n",
    "            The function's documentation is accessible by Shift+Tab.\n",
    "            \n",
    "            This function analyses a list of tokens using pymorphy2 and hashes result for faster processing.\n",
    "            \n",
    "            words - list of words.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w in self.__cash:\n",
    "                res.append(self.__cash[w])\n",
    "            else:\n",
    "                r = self.__morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.__cash[w] = r\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания объекта необходимо вызвать функцию с тем же именем, что и имя его типа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = FasterMorphology()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть переменная нужного типа и мы можем обращаться к ее полям, а также вызывать ее методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 779 ms, sys: 56 µs, total: 779 ms\n",
      "Wall time: 778 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = fast.analyzeWords(words) # Нажмите Shift+Tab чтобы посмотреть документацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев',\n",
       " 'николаевич',\n",
       " 'толстой',\n",
       " 'война',\n",
       " 'и',\n",
       " 'мир',\n",
       " 'тот',\n",
       " 'часть',\n",
       " 'первый',\n",
       " 'быть']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь еще раз то же самое, но с заполненным кешем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.2 ms, sys: 422 µs, total: 73.6 ms\n",
      "Wall time: 73.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res=fast.analyzeWords(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ускорение еще в 10 раз!<br>\n",
    "Правда, заодно мы выяснили, что слова надо приводить к единому написанию, устраняя, например, заглавные буквы. Повторим эксперимент без них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", textWP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast2 = FasterMorphology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 780 ms, sys: 4.02 ms, total: 784 ms\n",
      "Wall time: 784 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res=fast2.analyzeWords(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем следующую модификацию нашего класса. Мы хотим, чтобы пользователь мог выбирать с какой системой морфологического анализа работать - PyMorphy или MyStem. Для этого мы создадим две функции каждая из которых отвечает за свою систему. Обе эти функции будут обеспечивать унифицированный интерфейс, принимая на вход список токенов и выдавая список начальных форм. Вообще-то следовало бы передавать на вход строку с текстом, чтобы в случае PyMorphy самим проводить токенизацию, но нам отчего-то захотелось сохранить предыдущий интерфейс (унаследованная система?). \n",
    "\n",
    "В конструкторе (функция `__init__`) мы создадим объект морфологии нужного типа и сохраним в свойство класса `self.analyzeWords` функцию анализа, соответствующую переданному пользователем парамету. Теперь для проведения морфологического анализа необходимо вызвать `self.analyzeWords`, но при этом соверешнно не обязательно знать каким образом был проинициализирован объект нашего класса и какую систему морфологического анализа он использует. Унифицированный интерфейс позволяет пользователю не задумываться над этими вопросами, просто получая результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ключевое слово class после которого идет название нашего класса.\n",
    "class FasterMorphologyUnified:\n",
    "    \n",
    "    def __init__(self, dict_type: str): # Функция инициализации объекта после его создания.\n",
    "        # Создаем новую морфологию в каждом объекте. \n",
    "        # А вдруг мы будем потом работать с разными языками? У каждого объекта должна быть своя.\n",
    "        if dict_type == 'PyM':\n",
    "            self.morpho = pymorphy2.MorphAnalyzer() \n",
    "            self.cash = {} # Создаем словарь для кеширования.\n",
    "            self.analyzeWords = self.analyzeWordsWithPymorphy\n",
    "        elif dict_type == 'MyS':\n",
    "            self.mystem = pymystem3.Mystem()\n",
    "            self.analyzeWords = self.analyzeWordsWithMystem\n",
    "        # Вообще-то надо предусмотреть вариант, если нам передали какое-то еще значение, которого мы не знаем.\n",
    "        self.mode = dict_type # Сохраним, чтобы потом можно было понять что за словарь использовался.\n",
    "            \n",
    "    def analyzeWordsWithMystem(self, words: list) -> list:\n",
    "        \"\"\" Функция анализа при помощи MyStem.\n",
    "            words - список токенов для анализа.\n",
    "        \"\"\"\n",
    "        text = ' '.join(words)\n",
    "        tokens = self.mystem.analyze(text)\n",
    "        res = []\n",
    "        for t in tokens:\n",
    "            if 'analysis' in t.keys():\n",
    "                if t['analysis'] != []:\n",
    "                    res.append(t['analysis'][0]['lex'] + '_' + t['analysis'][0]['gr'][0])\n",
    "                else:\n",
    "                    res.append(t['text'] + '_' + 'U')\n",
    "        return res    \n",
    "\n",
    "    def analyzeWordsWithPymorphy(self, words: list) -> list:\n",
    "        \"\"\" Функция анализа при помощи PyMorphy.\n",
    "            words - список токенов для анализа.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w in self.cash:\n",
    "                res.append(self.cash[w])\n",
    "            else:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.cash[w] = r\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fast3 = FasterMorphologyUnified('MyS')#('PyM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 14.3 s, total: 2min 22s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res=fast3.analyzeWords(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Векторизация текстов</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем класс, отвечающий за векторизацию текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Другое имя класса, так как он обладает несколько иной функциональностью.\n",
    "class FasterMorphology2:\n",
    "    \"\"\" Класс для быстрого морфологического анализа текстов и их векторизации.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self): # Функция инициализации объекта после его создания.\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        self.__cash = {}\n",
    "        self.__dictionary = {} # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        \n",
    "    def analyzeWords(self, words: list) -> list:\n",
    "        \"\"\" Проводит морфологический анализ списка токенов words.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        res: list\n",
    "            \n",
    "        res=[]\n",
    "        for w in words:\n",
    "            if w in self.__cash: # Сперва ищем очередное слово в кеше.\n",
    "                res.append(self.__cash[w])\n",
    "            else: # Если его там нет, проводим морфологический анализ и кешируем.\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.__cash[w] = r\n",
    "                if r not in self.__dictionary: # Также для каждой начальной формы запоминаем ее позицию в векторе.\n",
    "                    self.dictionary[r] = len(self.dictionary) + 1\n",
    "        return res\n",
    "    \n",
    "    def analyzeText(self, text: str) -> list:\n",
    "        \"\"\" Проводит морфологический анализ строки с текстом text. \n",
    "            Выделяет из нее слова, написанные русской кириллицей.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        words: list\n",
    "        \n",
    "        words = [w[0] for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "        return self.analyzeWords(words)\n",
    "        \n",
    "    # Вообще-то тоже самое умеет Counter, но ему надо сперва привести слова к начальной форме.\n",
    "    def vectorizeAsDict(self, words) -> dict:\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct: dict\n",
    "        res: list\n",
    "        \n",
    "        vct = {}\n",
    "        res = []\n",
    "        for w in words: # Для каждого слова проводим анализ.\n",
    "            if w in self.__cash:\n",
    "                vct[self.__cash[w]] = vct.get(self.__cash[w], 0) + 1 # Считаем частоты слов.\n",
    "            else:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.__cash[w] = r\n",
    "                vct[r] = vct.get(r, 0) + 1\n",
    "                if r not in self.__dictionary:\n",
    "                    self.__dictionary[r] = len(self.__dictionary)\n",
    "        return vct\n",
    "    \n",
    "    def clearDict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "    \n",
    "    def formDict(self, texts: list):\n",
    "        \"\"\" Сформировать словарь по тексту не формируя разметку текста.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                if word not in self.cash:\n",
    "                    r = self.morpho.parse(w)[0].normal_form\n",
    "                    self.__cash[word] = r\n",
    "                    if r not in self.__dictionary:\n",
    "                        self.__dictionary[r] = len(self.__dictionary)\n",
    "    \n",
    "    def vectorizeAsList(self, words: list) -> list:\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.__cash:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                self.__cash[word] = r\n",
    "                if r not in self.__dictionary:\n",
    "                    self.__dictionary[r]=len(self.__dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = [0 for _ in self.__dictionary]\n",
    "        for word in words:\n",
    "            vct[self.__dictionary[self.__cash[word]]] += 1\n",
    "        return vct\n",
    "    \n",
    "    def vectorizeAsList2(self, words: list) -> list:\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words. В вектор включаются только слова, находящиес в словаре.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct = [0 for _ in self.__dictionary]\n",
    "        for word in words:\n",
    "            if word in self.__cash:\n",
    "                vct[self.__dictionary[self.__cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsArray(self, words: list) ->list:\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного массива (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.__cash:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.__dictionary:\n",
    "                    self.__dictionary[r]=len(self.__dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = np.zeros((len(self.__dictionary)))\n",
    "        for word in words:\n",
    "            vct[self.__dictionary[self.__cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    # Здесь мы заложили проблему. Функция не умеет считать расстояние между np.array.\n",
    "    # А ещё эти две функции не имеют никакого отношения к морфологическому анализу.\n",
    "    # Но представим себе, что мы завели ещё две функции, которые считают расстояние между текстами, а не векторами.\n",
    "    def cosineSimilarity(self, a, b) -> float:\n",
    "        \"\"\" Функция расчета косинусной меры сходства между двумя векторными представлениями текста.\n",
    "            Работает по-разному в зависимости от представления вектора.\n",
    "        \"\"\"\n",
    "        if type(a) != type(b): # Тип векторов должен совпадать.\n",
    "            return None\n",
    "        if isinstance(a, list): # Если это списки, значит это плотное представление вектора.\n",
    "            if 0 == len(a) or 0 == len(b) or len(a) != len(b): # Длины векторов в этом случае должны совпадать.\n",
    "                return 0\n",
    "            sumab = sum([a[na] * b[na] for na in range(len(a))])\n",
    "            suma2 = sum([a[na] * a[na] for na in range(len(a))])\n",
    "            sumb2 = sum([b[na] * b[na] for na in range(len(a))])\n",
    "            return sumab / math.sqrt(suma2 * sumb2)        \n",
    "        elif isinstance(a, dict): # Разреженное представление вектора - хранятся только ненулевые значения.\n",
    "            if 0 == len(a.keys()) or 0 == len(b.keys()): # Вектора должны хранить хоть что-то.\n",
    "                return 0\n",
    "            sumab = sum([a[na] * b[na] for na in set(a.keys()) & set(b.keys())])\n",
    "#            sumab=sum([a[na]*b[na] for na in a.keys() if na in b.keys()])\n",
    "            suma2 = sum([a[na] * a[na] for na in a.keys()])\n",
    "            sumb2 = sum([b[nb] * b[nb] for nb in b.keys()])\n",
    "            return sumab / math.sqrt(suma2 * sumb2)  \n",
    "        return 0\n",
    "    \n",
    "    def JaccardCoefficient(self, a, b) -> float:\n",
    "        \"\"\" Коэффициент Жаккара - отношение количества слов, встречающихся в обоих текстах к объединению лексики.\n",
    "        \"\"\"\n",
    "        if type(a) != type(b): # Тип векторов должен совпадать.\n",
    "            return None\n",
    "        if isinstance(a, list): # Если это списки, значит это плотное представление вектора.\n",
    "            if 0 == len(a) or 0 == len(b) or len(a) != len(b): # Длины векторов в этом случае должны совпадать.\n",
    "                return 0\n",
    "            union = len(a) - [aa * bb for aa, bb in zip(a, b)].count(0)\n",
    "            intersection = len(a) - [aa + bb for aa, bb in zip(a, b)].count(0)\n",
    "            return union / intersection\n",
    "        elif isinstance(a, dict): # Разреженное представление вектора - хранятся только ненулевые значения.\n",
    "            if 0 == len(a.keys()) or 0 == len(b.keys()): # Вектора должны хранить хоть что-то.\n",
    "                return 0\n",
    "            return len(set(a.keys()) & set(b.keys())) / len(set(a.keys()) | set(b.keys()))\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения меры сходства двух текстов используется косинусная мера сходства, рассчитываемая по следующей формуле: $cos(a,b)=\\frac{\\sum{a_i * b_i}}{\\sqrt {\\sum{a_i^2}*\\sum{b_i^2}}}$.<br>\n",
    "Вообще-то, использовать стандартную функцию рассчета косинусной меры сходства из <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\">sklearn</a> было бы быстрее. Но мне хотелось показать как работать с разными типами входа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как работает новая морфология. Возьмем также один из \"Севастопольских рассказов\" того же автора, чтобы было что использовать при расчете косинусной меры сходства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster3 = FasterMorphology2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sebastopol.txt') as fil:\n",
    "    textWP = fil.read()\n",
    "words3 = [w[0].lower() for w in re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textWP)]\n",
    "newtext3 = ' '.join(words3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим плотное и разреженное представление для двух текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd1 = faster3.vectorizeAsDict(words)\n",
    "vd2 = faster3.vectorizeAsDict(words3)\n",
    "vl1 = faster3.vectorizeAsList(words)\n",
    "vl2 = faster3.vectorizeAsList(words3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как быстро считается разреженное и плотное предствления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 3.34 µs\n",
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 3.58 µs\n",
      "0.9561367711772639 0.9561367711772639\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "r1 = faster3.cosineSimilarity(vd1, vd2)\n",
    "%time\n",
    "r2 = faster3.cosineSimilarity(vl1, vl2)\n",
    "print(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529 15350 18840\n"
     ]
    }
   ],
   "source": [
    "print(vl1.count(0), vl2.count(0), len(vl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 4.53 µs\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n",
      "0.1571656050955414 0.1571656050955414\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "r1 = faster3.JaccardCoefficient(vd1, vd2)\n",
    "%time\n",
    "r2 = faster3.JaccardCoefficient(vl1, vl2)\n",
    "print(r1, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько наши вектора занимают памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589920\n",
      "153752\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.getsizeof(vd1))\n",
    "print(sys.getsizeof(vl1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница по памяти в 4 раза. Попробуем с numpy.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150824\n"
     ]
    }
   ],
   "source": [
    "va1 = faster3.vectorizeAsArray(words)\n",
    "print(sys.getsizeof(va1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь какой-то небольшой выигрыш. Мораль - проще разработать свой собственный класс для разреженного хранения на основе общего для всех словаря с индексом и двумя массивами для индекса слов конкретного текста и их частот.\n",
    "\n",
    "Хорошо, продолжим с косинусной мерой. Попробуем посчитать сходство с \"Марсианином\" Энди Вейра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/veyr/index_split_017.xhtml') as fil: # Грузим главу 17, она побольше.\n",
    "    textM17 = fil.read()\n",
    "words4 = [w[0].lower() for w in re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textM17)]\n",
    "newtext4 = ' '.join(words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем вектора.\n",
    "vd3 = faster3.vectorizeAsDict(words4)\n",
    "vl3 = faster3.vectorizeAsList(words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853540382103844\n",
      "0.7776684489226509\n",
      "CPU times: user 13 ms, sys: 167 µs, total: 13.2 ms\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(faster3.cosineSimilarity(vd1, vd3))\n",
    "print(faster3.cosineSimilarity(vd2, vd3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "CPU times: user 386 µs, sys: 0 ns, total: 386 µs\n",
      "Wall time: 256 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(faster3.cosineSimilarity(vl1, vl3))\n",
    "print(faster3.cosineSimilarity(vl2, vl3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то пошло не так. Постараемся понять что именно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52011/5167731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msumab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvl3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msuma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msumb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvl3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msumab\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuma2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msumb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52011/5167731.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msumab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvl3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msuma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msumb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvl3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msumab\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuma2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msumb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sumab = sum([vl1[na] * vl3[na] for na in range(len(vl3))])\n",
    "suma2 = sum([vl1[na] * vl1[na] for na in range(len(vl3))])\n",
    "sumb2 = sum([vl3[na] * vl3[na] for na in range(len(vl3))])\n",
    "sumab / math.sqrt(suma2 * sumb2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну конечно же! Надо же пересчитать все вектора, а то размерность пространства изменилась! Со словарями такой проблемы не было."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl1 = faster3.vectorizeAsList(words)\n",
    "vl2 = faster3.vectorizeAsList(words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853540382103844\n",
      "0.7776684489226509\n",
      "CPU times: user 22.5 ms, sys: 0 ns, total: 22.5 ms\n",
      "Wall time: 21.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(faster3.cosineSimilarity(vl1, vl3))\n",
    "print(faster3.cosineSimilarity(vl2, vl3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 15777, 17677, 19267)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl1.count(0), vl2.count(0), vl3.count(0), len(vl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем построить вектора для всего текста \"Марсианина\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words5 = []\n",
    "for i in range(2, 33):\n",
    "    with open(f'data/veyr/index_split_0{i:0>2}.xhtml') as fil:\n",
    "        textMar = fil.read()\n",
    "    words6 = [w[0].lower() for w in re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textMar)]\n",
    "    words5 += words6\n",
    "newtext5 = ' '.join(words5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd4 = faster3.vectorizeAsDict(words5)\n",
    "vl4 = faster3.vectorizeAsList(words5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl1 = faster3.vectorizeAsList(words)\n",
    "vl2 = faster3.vectorizeAsList(words3)\n",
    "vl3 = faster3.vectorizeAsList(words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8039365043485874\n",
      "0.8083884676412758\n",
      "0.8816806000490218\n",
      "CPU times: user 23.6 ms, sys: 663 µs, total: 24.3 ms\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(faster3.cosineSimilarity(vd1, vd4))\n",
    "print(faster3.cosineSimilarity(vd2, vd4))\n",
    "print(faster3.cosineSimilarity(vd3, vd4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, глава из \"Марсианина\" больше похожа на всё произведение, чем на Толстого. Но общая мера сходства довольно большая. То есть по-хорошему, речь идет в большой степени об одинаковых вещах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8039365043485874\n",
      "0.8083884676412758\n",
      "0.8816806000490218\n",
      "CPU times: user 34.7 ms, sys: 394 µs, total: 35.1 ms\n",
      "Wall time: 33.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(faster3.cosineSimilarity(vl1, vl4))\n",
    "print(faster3.cosineSimilarity(vl2, vl4))\n",
    "print(faster3.cosineSimilarity(vl3, vl4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18311 3490 1590 8011 22241\n",
      "445508 90841\n"
     ]
    }
   ],
   "source": [
    "print(len(vl1) - vl1.count(0), \n",
    "      len(vl1) - vl2.count(0), \n",
    "      len(vl1) - vl3.count(0), \n",
    "      len(vl1) - vl4.count(0), \n",
    "      len(vl1))\n",
    "print(len(words), len(words5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104178\n",
      "8736\n"
     ]
    }
   ],
   "source": [
    "with open('data/war_and_peace3.txt') as fil:\n",
    "    textWP = fil.read()\n",
    "words6 = [w[0] for w in re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textWP)]\n",
    "print(len(words6))\n",
    "faster4 = FasterMorphology2()\n",
    "vd5 = faster4.vectorizeAsDict(words6)\n",
    "vl5 = faster4.vectorizeAsList(words6)\n",
    "print(len(vl5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CountVectorizer и TfidfVectorizer</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле примерно всё то же самое можно селать при помощи класса CountVectorizer из sklearn.feature_extraction.text. При помощи функции <i>fit\\_transform</i> можно получить разреженное представление матрицы частот слов. Основная проблема состоит в том, что индексы в матрице представляют собой индексы в словаре переданных текстов. Сам словарь хранится в свойстве <i>vocabulary\\_</i> и умеет возвращать индекс по слову (но не наоборот)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t10\n",
      "  (0, 6)\t7\n",
      "  (0, 7)\t3\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 9)\t3\n",
      "20342\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "counter = CountVectorizer()\n",
    "# Просим посчитать частоты слов.\n",
    "res = counter.fit_transform([newtext, newtext3, newtext5])\n",
    "# Разреженное представление счетчика.\n",
    "print(res[0][0,:10])\n",
    "# Можно получить индекс по слову, ...\n",
    "print(counter.vocabulary_.get('левый'))\n",
    "# ... но не наоборот.\n",
    "print(counter.vocabulary_.get(20342))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более того, CountVectorizer просто выделяет подстроки и ничего не знает про морфологию (ее можно правильно прикрутить, но это хлопотное занятие). Зато он умеет выделять n-граммы (n слов идущих подряд (или даже букв)). Помимо этого, можно попросить выдать все подстроки, создав анализатор. И можно сказать как выделять подстроки при помощи регулярного выражения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeaningfullWords(text):\n",
    "    words = []\n",
    "    tokens = re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', text)\n",
    "    for t in tokens:\n",
    "        pv = morph.parse(t)\n",
    "        if pv[0].tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']:\n",
    "            words.append(pv[0].normal_form)\n",
    "    return words\n",
    "\n",
    "lemmaCounter = CountVectorizer(ngram_range=(1,3), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "\n",
    "c = [' '.join(getMeaningfullWords(newtext)),\n",
    "     ' '.join(getMeaningfullWords(newtext3)),\n",
    "     ' '.join(getMeaningfullWords(newtext5))]\n",
    "analyze = lemmaCounter.build_analyzer()\n",
    "res1 = analyze(c[0])\n",
    "res2 = lemmaCounter.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лев', 'николаевич', 'толстой', 'война', 'мир', 'тот', 'часть', 'первый', 'быть', 'поместье']\n"
     ]
    }
   ],
   "source": [
    "print(res1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем другой показатель для подсчета важности слов в тексте - $TF*IDF$. Здесь $TF$ - Term Frequency, частота термина в документе, а $IDF$ - Inverted Document Frequency, обратная частота термина в коллекции (количество документов, в которых встречается данный термин).\n",
    "\n",
    "Идея метрики очень проста. Если слово встречается почти во всех документах - его различительная сила очень мала и само слово не является важным. Если слово часто встречается в данном документе, то оно являетсяя важным для него.\n",
    "\n",
    "Метрика считается на коллекции документов для каждого слова, каждого документа. Для расчета меры можно использовать `TfidfVectorizer`, который работает так же как `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmaCounter = TfidfVectorizer(ngram_range=(1,3), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "\n",
    "c = [' '.join(getMeaningfullWords(newtext)),\n",
    "     ' '.join(getMeaningfullWords(newtext3)),\n",
    "     ' '.join(getMeaningfullWords(newtext5))]\n",
    "analyze = lemmaCounter.build_analyzer()\n",
    "res1 = analyze(c[0])\n",
    "res2 = lemmaCounter.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t0.00011569805879228521\n",
      "  (0, 5)\t0.00011569805879228521\n",
      "  (0, 1)\t0.00011569805879228521\n",
      "  (0, 4)\t0.00011569805879228521\n",
      "  (0, 9)\t0.00023139611758457042\n",
      "  (0, 0)\t0.00011569805879228521\n",
      "  (0, 3)\t0.00011569805879228521\n"
     ]
    }
   ],
   "source": [
    "print(res2[0][0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем посмотреть на близость глав \"Марсианина\" при помощи косинусной меры по частотам слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsM = []\n",
    "for i in range(2, 33):\n",
    "    with open(f'data/veyr/index_split_0{i:0>2}.xhtml') as fil:\n",
    "        textWP = fil.read()\n",
    "    words6 = [w[0].lower() for w in re.findall('([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)', textWP)]\n",
    "    wordsM.append(words6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_vects = []\n",
    "\n",
    "for words in wordsM:\n",
    "    m_vects.append(faster3.vectorizeAsDict(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420221325678382 22 25\n"
     ]
    }
   ],
   "source": [
    "nearest = -1\n",
    "txt1 = -1\n",
    "txt2 = -1\n",
    "for i, vct1 in enumerate(m_vects):\n",
    "    for j, vct2 in enumerate(m_vects):\n",
    "        if vct1 is vct2:\n",
    "            continue\n",
    "        cc = faster3.cosineSimilarity(vct1, vct2)\n",
    "        if cc > nearest:\n",
    "            nearest = cc\n",
    "            txt1 = i\n",
    "            txt2 = j\n",
    "print(nearest, txt1+2, txt2+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь возьмем косинусную меру сходства по результатам TF*IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "textM = []\n",
    "for i in range(2, 33):\n",
    "    with open(f'data/veyr/index_split_0{i:0>2}.xhtml') as fil:\n",
    "        textM.append(fil.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmaCounter = CountVectorizer(ngram_range=(1,3), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "#lemmaCounter=TfidfVectorizer(ngram_range=(1,3), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "\n",
    "analyze = lemmaCounter.build_analyzer()\n",
    "#res1=analyze(c[0])\n",
    "res2 = lemmaCounter.fit_transform(textM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85149324]] 15 21\n"
     ]
    }
   ],
   "source": [
    "nearest = -1\n",
    "txt1 = -1\n",
    "txt2 = -1\n",
    "for i, vct1 in enumerate(res2):\n",
    "    for j, vct2 in enumerate(res2):\n",
    "        if i==j:\n",
    "            continue\n",
    "        cc = cosine_similarity(vct1, vct2)\n",
    "        if cc > nearest:\n",
    "            nearest = cc\n",
    "            txt1 = i\n",
    "            txt2 = j\n",
    "print(nearest, txt1+2, txt2+2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Из чего же сделаны классы?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на объект изнутри. Мы уже обратили внимание, что объект класса надо пересоздать после внесения изменения в класс. Получается, что каждый объект \"носит\" с собой все свои функции.<br>\n",
    "Среди прочего, это связано с тем, что Питон работает со ссылками на переменные, а не самими переменными. Переменная в Питоне - это не классический \"ящик\" в котором хранится значение. Это ссылка на подобный ящик.<br>\n",
    "Функция <i>dir</i> выдает список всех полей и методов объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JaccardCoefficient',\n",
       " '_FasterMorphology2__cash',\n",
       " '_FasterMorphology2__dictionary',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'analyzeText',\n",
       " 'analyzeWords',\n",
       " 'clearDict',\n",
       " 'cosineSimilarity',\n",
       " 'formDict',\n",
       " 'morpho',\n",
       " 'vectorizeAsArray',\n",
       " 'vectorizeAsDict',\n",
       " 'vectorizeAsList',\n",
       " 'vectorizeAsList2']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(faster3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А поле \\__dict\\__ хранит только поля объекта. Но собственно хранит, а не содержит список названий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'morpho': <pymorphy2.analyzer.MorphAnalyzer at 0x7f95d2240760>,\n",
       " '_FasterMorphology2__cash': {'Лев': 'лев',\n",
       "  'Николаевич': 'николаевич',\n",
       "  'Толстой': 'толстой',\n",
       "  'Война': 'война',\n",
       "  'и': 'и',\n",
       "  'мир': 'мир',\n",
       "  'Том': 'тот',\n",
       "  'ЧАСТЬ': 'часть',\n",
       "  'ПЕРВАЯ': 'первый',\n",
       "  'Е': 'быть',\n",
       "  'поместья': 'поместье',\n",
       "  'мой': 'мой',\n",
       "  'верный': 'верный',\n",
       "  'раб': 'раб',\n",
       "  'Ну': 'ну',\n",
       "  'здравствуйте': 'здравствуйте',\n",
       "  'садитесь': 'садиться',\n",
       "  'рассказывайте': 'рассказывать',\n",
       "  'Так': 'так',\n",
       "  'говорила': 'говорить',\n",
       "  'в': 'в',\n",
       "  'июле': 'июль',\n",
       "  'года': 'год',\n",
       "  'известная': 'известный',\n",
       "  'Анна': 'анна',\n",
       "  'Павловна': 'павлович',\n",
       "  'Шерер': 'шерер',\n",
       "  'фрейлина': 'фрейлина',\n",
       "  'приближенная': 'приблизить',\n",
       "  'императрицы': 'императрица',\n",
       "  'Марии': 'мария',\n",
       "  'Феодоровны': 'феодоровный',\n",
       "  'встречая': 'встречать',\n",
       "  'важного': 'важный',\n",
       "  'чиновного': 'чиновный',\n",
       "  'князя': 'князь',\n",
       "  'Василия': 'василий',\n",
       "  'первого': 'первый',\n",
       "  'приехавшего': 'приехать',\n",
       "  'на': 'на',\n",
       "  'ее': 'она',\n",
       "  'вечер': 'вечер',\n",
       "  'кашляла': 'кашлять',\n",
       "  'несколько': 'несколько',\n",
       "  'дней': 'день',\n",
       "  'у': 'у',\n",
       "  'нее': 'она',\n",
       "  'был': 'быть',\n",
       "  'грипп': 'грипп',\n",
       "  'как': 'как',\n",
       "  'она': 'она',\n",
       "  'тогда': 'тогда',\n",
       "  'новое': 'новый',\n",
       "  'слово': 'слово',\n",
       "  'употреблявшееся': 'употребляться',\n",
       "  'только': 'только',\n",
       "  'редкими': 'редкий',\n",
       "  'В': 'в',\n",
       "  'записочках': 'записочка',\n",
       "  'разосланных': 'разослать',\n",
       "  'утром': 'утром',\n",
       "  'с': 'с',\n",
       "  'красным': 'красный',\n",
       "  'лакеем': 'лакей',\n",
       "  'было': 'быть',\n",
       "  'написано': 'написать',\n",
       "  'без': 'без',\n",
       "  'различия': 'различие',\n",
       "  'во': 'в',\n",
       "  'всех': 'весь',\n",
       "  'или': 'или',\n",
       "  'отвечал': 'отвечать',\n",
       "  'нисколько': 'нисколько',\n",
       "  'не': 'не',\n",
       "  'смутясь': 'смутиться',\n",
       "  'такою': 'такой',\n",
       "  'встречей': 'встреча',\n",
       "  'вошедший': 'войти',\n",
       "  'князь': 'князь',\n",
       "  'придворном': 'придворный',\n",
       "  'шитом': 'шитый',\n",
       "  'мундире': 'мундир',\n",
       "  'чулках': 'чулок',\n",
       "  'башмаках': 'башмак',\n",
       "  'при': 'при',\n",
       "  'звездах': 'звезда',\n",
       "  'светлым': 'светлый',\n",
       "  'выражением': 'выражение',\n",
       "  'плоского': 'плоский',\n",
       "  'лица': 'лицо',\n",
       "  'Он': 'он',\n",
       "  'говорил': 'говорить',\n",
       "  'том': 'тот',\n",
       "  'изысканном': 'изысканный',\n",
       "  'французском': 'французский',\n",
       "  'языке': 'язык',\n",
       "  'котором': 'который',\n",
       "  'говорили': 'говорить',\n",
       "  'но': 'но',\n",
       "  'думали': 'думать',\n",
       "  'наши': 'наш',\n",
       "  'деды': 'дед',\n",
       "  'теми': 'тот',\n",
       "  'тихими': 'тихий',\n",
       "  'покровительственными': 'покровительственный',\n",
       "  'интонациями': 'интонация',\n",
       "  'которые': 'который',\n",
       "  'свойственны': 'свойственный',\n",
       "  'состаревшемуся': 'состаревшийся',\n",
       "  'свете': 'свет',\n",
       "  'дворе': 'двор',\n",
       "  'значительному': 'значительный',\n",
       "  'человеку': 'человек',\n",
       "  'подошел': 'подойти',\n",
       "  'к': 'к',\n",
       "  'Анне': 'анне',\n",
       "  'Павловне': 'павлович',\n",
       "  'поцеловал': 'поцеловать',\n",
       "  'руку': 'рука',\n",
       "  'подставив': 'подставить',\n",
       "  'ей': 'она',\n",
       "  'свою': 'свой',\n",
       "  'надушенную': 'надушить',\n",
       "  'сияющую': 'сиять',\n",
       "  'лысину': 'лысина',\n",
       "  'покойно': 'покойно',\n",
       "  'уселся': 'усесться',\n",
       "  'диване': 'диван',\n",
       "  'Успокойте': 'успокоить',\n",
       "  'друга': 'друг',\n",
       "  'сказал': 'сказать',\n",
       "  'он': 'он',\n",
       "  'изменяя': 'изменять',\n",
       "  'голоса': 'голос',\n",
       "  'тоном': 'тон',\n",
       "  'из-за': 'из-за',\n",
       "  'приличия': 'приличие',\n",
       "  'участия': 'участие',\n",
       "  'просвечивало': 'просвечивать',\n",
       "  'равнодушие': 'равнодушие',\n",
       "  'даже': 'даже',\n",
       "  'насмешка': 'насмешка',\n",
       "  'Как': 'как',\n",
       "  'можно': 'можно',\n",
       "  'быть': 'быть',\n",
       "  'здоровой': 'здоровый',\n",
       "  'когда': 'когда',\n",
       "  'нравственно': 'нравственно',\n",
       "  'страдаешь': 'страдать',\n",
       "  'Разве': 'разве',\n",
       "  'оставаться': 'оставаться',\n",
       "  'спокойною': 'спокойный',\n",
       "  'наше': 'наш',\n",
       "  'время': 'время',\n",
       "  'есть': 'есть',\n",
       "  'человека': 'человек',\n",
       "  'чувство': 'чувство',\n",
       "  'сказала': 'сказать',\n",
       "  'Вы': 'вы',\n",
       "  'весь': 'весь',\n",
       "  'меня': 'я',\n",
       "  'надеюсь': 'надеяться',\n",
       "  'А': 'а',\n",
       "  'праздник': 'праздник',\n",
       "  'английского': 'английский',\n",
       "  'посланника': 'посланник',\n",
       "  'Нынче': 'нынче',\n",
       "  'середа': 'середа',\n",
       "  'Мне': 'я',\n",
       "  'надо': 'надо',\n",
       "  'показаться': 'показаться',\n",
       "  'там': 'там',\n",
       "  'Дочь': 'дочь',\n",
       "  'заедет': 'заехать',\n",
       "  'за': 'за',\n",
       "  'мной': 'я',\n",
       "  'повезет': 'повезти',\n",
       "  'Я': 'я',\n",
       "  'думала': 'думать',\n",
       "  'что': 'что',\n",
       "  'нынешний': 'нынешний',\n",
       "  'отменен': 'отменный',\n",
       "  'Ежели': 'ежели',\n",
       "  'бы': 'бы',\n",
       "  'знали': 'знать',\n",
       "  'вы': 'вы',\n",
       "  'этого': 'это',\n",
       "  'хотите': 'хотеть',\n",
       "  'отменили': 'отменить',\n",
       "  'по': 'по',\n",
       "  'привычке': 'привычка',\n",
       "  'заведенные': 'завести',\n",
       "  'часы': 'часы',\n",
       "  'говоря': 'говорить',\n",
       "  'вещи': 'вещь',\n",
       "  'которым': 'который',\n",
       "  'хотел': 'хотеть',\n",
       "  'чтобы': 'чтобы',\n",
       "  'верили': 'верить',\n",
       "  'вам': 'вы',\n",
       "  'сказать': 'сказать',\n",
       "  'холодным': 'холодный',\n",
       "  'скучающим': 'скучать',\n",
       "  'Князь': 'князь',\n",
       "  'Василий': 'василий',\n",
       "  'всегда': 'всегда',\n",
       "  'лениво': 'лениво',\n",
       "  'актер': 'актёр',\n",
       "  'говорит': 'говорить',\n",
       "  'роль': 'роль',\n",
       "  'старой': 'старый',\n",
       "  'пиесы': 'пиес',\n",
       "  'напротив': 'напротив',\n",
       "  'несмотря': 'несмотря',\n",
       "  'свои': 'свой',\n",
       "  'сорок': 'сорок',\n",
       "  'лет': 'год',\n",
       "  'была': 'быть',\n",
       "  'преисполнена': 'преисполнить',\n",
       "  'оживления': 'оживление',\n",
       "  'порывов': 'порыв',\n",
       "  'Быть': 'быть',\n",
       "  'энтузиасткой': 'энтузиастка',\n",
       "  'сделалось': 'сделаться',\n",
       "  'общественным': 'общественный',\n",
       "  'положением': 'положение',\n",
       "  'иногда': 'иногда',\n",
       "  'того': 'тот',\n",
       "  'хотелось': 'хотеться',\n",
       "  'обмануть': 'обмануть',\n",
       "  'ожиданий': 'ожидание',\n",
       "  'людей': 'человек',\n",
       "  'знавших': 'знать',\n",
       "  'делалась': 'делаться',\n",
       "  'Сдержанная': 'сдержать',\n",
       "  'улыбка': 'улыбка',\n",
       "  'игравшая': 'играть',\n",
       "  'постоянно': 'постоянно',\n",
       "  'лице': 'лицо',\n",
       "  'Анны': 'анна',\n",
       "  'Павловны': 'павлович',\n",
       "  'хотя': 'хотя',\n",
       "  'шла': 'идти',\n",
       "  'отжившим': 'отживший',\n",
       "  'чертам': 'черта',\n",
       "  'выражала': 'выражать',\n",
       "  'избалованных': 'избаловать',\n",
       "  'детей': 'ребёнок',\n",
       "  'постоянное': 'постоянный',\n",
       "  'сознание': 'сознание',\n",
       "  'своего': 'свой',\n",
       "  'милого': 'милый',\n",
       "  'недостатка': 'недостаток',\n",
       "  'от': 'от',\n",
       "  'которого': 'который',\n",
       "  'хочет': 'хотеть',\n",
       "  'может': 'мочь',\n",
       "  'находит': 'находить',\n",
       "  'нужным': 'нужный',\n",
       "  'исправляться': 'исправляться',\n",
       "  'середине': 'середина',\n",
       "  'разговора': 'разговор',\n",
       "  'про': 'про',\n",
       "  'политические': 'политический',\n",
       "  'действия': 'действие',\n",
       "  'разгорячилась': 'разгорячиться',\n",
       "  'Ах': 'ах',\n",
       "  'говорите': 'говорить',\n",
       "  'мне': 'я',\n",
       "  'Австрию': 'австрия',\n",
       "  'ничего': 'ничего',\n",
       "  'понимаю': 'понимать',\n",
       "  'Австрия': 'австрия',\n",
       "  'никогда': 'никогда',\n",
       "  'хотела': 'хотеть',\n",
       "  'войны': 'война',\n",
       "  'Она': 'она',\n",
       "  'предает': 'предавать',\n",
       "  'нас': 'мы',\n",
       "  'Россия': 'россия',\n",
       "  'одна': 'один',\n",
       "  'должна': 'должный',\n",
       "  'спасительницей': 'спасительница',\n",
       "  'Европы': 'европа',\n",
       "  'Наш': 'наш',\n",
       "  'благодетель': 'благодетель',\n",
       "  'знает': 'знать',\n",
       "  'свое': 'свой',\n",
       "  'высокое': 'высокий',\n",
       "  'призвание': 'призвание',\n",
       "  'будет': 'быть',\n",
       "  'верен': 'верный',\n",
       "  'ему': 'он',\n",
       "  'Вот': 'вот',\n",
       "  'одно': 'один',\n",
       "  'я': 'я',\n",
       "  'верю': 'верить',\n",
       "  'Нашему': 'наш',\n",
       "  'доброму': 'добрый',\n",
       "  'чудному': 'чудной',\n",
       "  'государю': 'государь',\n",
       "  'предстоит': 'предстоять',\n",
       "  'величайшая': 'великий',\n",
       "  'мире': 'мир',\n",
       "  'так': 'так',\n",
       "  'добродетелен': 'добродетельный',\n",
       "  'хорош': 'хороший',\n",
       "  'Бог': 'бог',\n",
       "  'оставит': 'оставить',\n",
       "  'его': 'он',\n",
       "  'исполнит': 'исполнить',\n",
       "  'задавить': 'задавить',\n",
       "  'гидру': 'гидра',\n",
       "  'революции': 'революция',\n",
       "  'которая': 'который',\n",
       "  'теперь': 'теперь',\n",
       "  'еще': 'ещё',\n",
       "  'ужаснее': 'ужасный',\n",
       "  'убийцы': 'убийца',\n",
       "  'злодея': 'злодей',\n",
       "  'Мы': 'мы',\n",
       "  'одни': 'один',\n",
       "  'должны': 'должный',\n",
       "  'искупить': 'искупить',\n",
       "  'кровь': 'кровь',\n",
       "  'праведника': 'праведник',\n",
       "  'На': 'на',\n",
       "  'кого': 'кто',\n",
       "  'нам': 'мы',\n",
       "  'надеяться': 'надеяться',\n",
       "  'вас': 'вы',\n",
       "  'спрашиваю': 'спрашивать',\n",
       "  'Англия': 'англия',\n",
       "  'своим': 'свой',\n",
       "  'коммерческим': 'коммерческий',\n",
       "  'духом': 'дух',\n",
       "  'поймет': 'понять',\n",
       "  'понять': 'понять',\n",
       "  'всю': 'весь',\n",
       "  'высоту': 'высота',\n",
       "  'души': 'душа',\n",
       "  'императора': 'император',\n",
       "  'Александра': 'александр',\n",
       "  'отказалась': 'отказаться',\n",
       "  'очистить': 'очистить',\n",
       "  'Мальту': 'мальта',\n",
       "  'видеть': 'видеть',\n",
       "  'ищет': 'искать',\n",
       "  'заднюю': 'задний',\n",
       "  'мысль': 'мысль',\n",
       "  'наших': 'наш',\n",
       "  'действий': 'действие',\n",
       "  'Что': 'что',\n",
       "  'они': 'они',\n",
       "  'сказали': 'сказать',\n",
       "  'Новосильцову': 'новосильцов',\n",
       "  'Ничего': 'ничего',\n",
       "  'Они': 'они',\n",
       "  'поняли': 'понять',\n",
       "  'могут': 'мочь',\n",
       "  'самоотвержения': 'самоотвержение',\n",
       "  'нашего': 'наш',\n",
       "  'который': 'который',\n",
       "  'для': 'для',\n",
       "  'себя': 'себя',\n",
       "  'все': 'всё',\n",
       "  'блага': 'благо',\n",
       "  'мира': 'мир',\n",
       "  'И': 'и',\n",
       "  'обещали': 'обещать',\n",
       "  'Пруссия': 'пруссия',\n",
       "  'уж': 'уж',\n",
       "  'объявила': 'объявить',\n",
       "  'Бонапарте': 'бонапарт',\n",
       "  'непобедим': 'непобедимый',\n",
       "  'вся': 'весь',\n",
       "  'Европа': 'европа',\n",
       "  'против': 'против',\n",
       "  'него': 'он',\n",
       "  'ни': 'ни',\n",
       "  'одном': 'один',\n",
       "  'слове': 'слово',\n",
       "  'Гарденбергу': 'гарденберг',\n",
       "  'Гаугвицу': 'гаугвица',\n",
       "  'одного': 'один',\n",
       "  'Бога': 'бог',\n",
       "  'высокую': 'высокий',\n",
       "  'судьбу': 'судьба',\n",
       "  'спасет': 'спасти',\n",
       "  'Европу': 'европа',\n",
       "  'вдруг': 'вдруг',\n",
       "  'остановилась': 'остановиться',\n",
       "  'улыбкою': 'улыбка',\n",
       "  'насмешки': 'насмешка',\n",
       "  'над': 'над',\n",
       "  'своею': 'свой',\n",
       "  'горячностью': 'горячность',\n",
       "  'думаю': 'думать',\n",
       "  'улыбаясь': 'улыбаться',\n",
       "  'ежели': 'ежели',\n",
       "  'послали': 'послать',\n",
       "  'вместо': 'вместо',\n",
       "  'Винценгероде': 'винценгерод',\n",
       "  'взяли': 'взять',\n",
       "  'приступом': 'приступ',\n",
       "  'согласие': 'согласие',\n",
       "  'прусского': 'прусский',\n",
       "  'короля': 'король',\n",
       "  'красноречивы': 'красноречивый',\n",
       "  'дадите': 'дать',\n",
       "  'чаю': 'чай',\n",
       "  'Сейчас': 'сейчас',\n",
       "  'прибавила': 'прибавить',\n",
       "  'опять': 'опять',\n",
       "  'успокоиваясь': 'успокоиваться',\n",
       "  'нынче': 'нынче',\n",
       "  'два': 'два',\n",
       "  'очень': 'очень',\n",
       "  'интересные': 'интересный',\n",
       "  'из': 'из',\n",
       "  'лучших': 'хороший',\n",
       "  'фамилий': 'фамилия',\n",
       "  'Франции': 'франция',\n",
       "  'Это': 'это',\n",
       "  'один': 'один',\n",
       "  'хороших': 'хороший',\n",
       "  'эмигрантов': 'эмигрант',\n",
       "  'настоящих': 'настоящий',\n",
       "  'потом': 'потом',\n",
       "  'знаете': 'знать',\n",
       "  'этот': 'этот',\n",
       "  'глубокий': 'глубокий',\n",
       "  'ум': 'ум',\n",
       "  'принят': 'принять',\n",
       "  'государем': 'государь',\n",
       "  'рад': 'рад',\n",
       "  'буду': 'быть',\n",
       "  'Скажите': 'сказать',\n",
       "  'прибавил': 'прибавить',\n",
       "  'будто': 'будто',\n",
       "  'вспомнив': 'вспомнить',\n",
       "  'что-то': 'что-то',\n",
       "  'особенно-небрежно': 'особенно-небрежно',\n",
       "  'то': 'то',\n",
       "  'о': 'о',\n",
       "  'чем': 'чем',\n",
       "  'спрашивал': 'спрашивать',\n",
       "  'главною': 'главный',\n",
       "  'целью': 'цель',\n",
       "  'посещения': 'посещение',\n",
       "  'правда': 'правда',\n",
       "  'желает': 'желать',\n",
       "  'назначения': 'назначение',\n",
       "  'барона': 'барон',\n",
       "  'Функе': 'функа',\n",
       "  'первым': 'первый',\n",
       "  'секретарем': 'секретарь',\n",
       "  'Вену': 'вена',\n",
       "  'желал': 'желать',\n",
       "  'определить': 'определить',\n",
       "  'сына': 'сын',\n",
       "  'это': 'это',\n",
       "  'место': 'место',\n",
       "  'которое': 'который',\n",
       "  'через': 'через',\n",
       "  'императрицу': 'императрица',\n",
       "  'Марию': 'мария',\n",
       "  'Феодоровну': 'феодорович',\n",
       "  'старались': 'стараться',\n",
       "  'доставить': 'доставить',\n",
       "  'барону': 'барон',\n",
       "  'почти': 'почти',\n",
       "  'закрыла': 'закрыть',\n",
       "  'глаза': 'глаз',\n",
       "  'знак': 'знак',\n",
       "  'кто': 'кто',\n",
       "  'другой': 'другой',\n",
       "  'судить': 'судить',\n",
       "  'угодно': 'угодный',\n",
       "  'нравится': 'нравиться',\n",
       "  'императрице': 'императрица',\n",
       "  'грустным': 'грустный',\n",
       "  'сухим': 'сухой',\n",
       "  'назвала': 'назвать',\n",
       "  'лицо': 'лицо',\n",
       "  'представило': 'представить',\n",
       "  'глубокое': 'глубокий',\n",
       "  'искреннее': 'искренний',\n",
       "  'выражение': 'выражение',\n",
       "  'преданности': 'преданность',\n",
       "  'уважения': 'уважение',\n",
       "  'соединенное': 'соединить',\n",
       "  'грустью': 'грусть',\n",
       "  'ней': 'она',\n",
       "  'бывало': 'бывало',\n",
       "  'каждый': 'каждый',\n",
       "  'раз': 'раз',\n",
       "  'разговоре': 'разговор',\n",
       "  'упоминала': 'упоминать',\n",
       "  'своей': 'свой',\n",
       "  'высокой': 'высокий',\n",
       "  'покровительнице': 'покровительница',\n",
       "  'величество': 'величество',\n",
       "  'изволила': 'изволить',\n",
       "  'оказать': 'оказать',\n",
       "  'взгляд': 'взгляд',\n",
       "  'подернулся': 'подёрнуться',\n",
       "  'равнодушно': 'равнодушно',\n",
       "  'замолк': 'замолкнуть',\n",
       "  'свойственною': 'свойственный',\n",
       "  'придворною': 'придворный',\n",
       "  'женскою': 'женский',\n",
       "  'ловкостью': 'ловкость',\n",
       "  'быстротою': 'быстрота',\n",
       "  'такта': 'такт',\n",
       "  'захотела': 'захотеть',\n",
       "  'щелконуть': 'щелконуть',\n",
       "  'дерзнул': 'дерзнуть',\n",
       "  'отозваться': 'отозваться',\n",
       "  'рекомендованном': 'рекомендовать',\n",
       "  'же': 'же',\n",
       "  'утешить': 'утешить',\n",
       "  'ли': 'ли',\n",
       "  'ваша': 'ваш',\n",
       "  'дочь': 'дочь',\n",
       "  'тех': 'тот',\n",
       "  'пор': 'пора',\n",
       "  'выезжает': 'выезжать',\n",
       "  'наклонился': 'наклониться',\n",
       "  'признательности': 'признательность',\n",
       "  'часто': 'часто',\n",
       "  'продолжала': 'продолжать',\n",
       "  'после': 'после',\n",
       "  'минутного': 'минутный',\n",
       "  'молчания': 'молчание',\n",
       "  'подвигаясь': 'подвигаться',\n",
       "  'князю': 'князь',\n",
       "  'ласково': 'ласково',\n",
       "  'выказывая': 'выказывать',\n",
       "  'этим': 'это',\n",
       "  'светские': 'светский',\n",
       "  'разговоры': 'разговор',\n",
       "  'кончены': 'конченый',\n",
       "  'начинается': 'начинаться',\n",
       "  'задушевный': 'задушевный',\n",
       "  'несправедливо': 'несправедливый',\n",
       "  'распределяется': 'распределяться',\n",
       "  'счастие': 'счастие',\n",
       "  'жизни': 'жизнь',\n",
       "  'За': 'за',\n",
       "  'судьба': 'судьба',\n",
       "  'дала': 'дать',\n",
       "  'таких': 'такой',\n",
       "  'двух': 'два',\n",
       "  'славных': 'славный',\n",
       "  'исключая': 'исключая',\n",
       "  'Анатоля': 'анатоль',\n",
       "  'вашего': 'ваш',\n",
       "  'меньшого': 'меньшой',\n",
       "  'люблю': 'любить',\n",
       "  'вставила': 'вставить',\n",
       "  'безапелляционно': 'безапелляционно',\n",
       "  'приподняв': 'приподнять',\n",
       "  'брови': 'бровь',\n",
       "  'прелестных': 'прелестный',\n",
       "  'право': 'право',\n",
       "  'менее': 'менее',\n",
       "  'цените': 'ценить',\n",
       "  'их': 'они',\n",
       "  'потому': 'потому',\n",
       "  'стоите': 'стоить',\n",
       "  'улыбнулась': 'улыбнуться',\n",
       "  'восторженною': 'восторженный',\n",
       "  'улыбкой': 'улыбка',\n",
       "  'Перестаньте': 'перестать',\n",
       "  'шутить': 'шутить',\n",
       "  'серьезно': 'серьёзно',\n",
       "  'поговорить': 'поговорить',\n",
       "  'вами': 'вы',\n",
       "  'Знаете': 'знать',\n",
       "  'недовольна': 'недовольный',\n",
       "  'вашим': 'ваш',\n",
       "  'меньшим': 'малый',\n",
       "  'сыном': 'сын',\n",
       "  'Между': 'между',\n",
       "  'нами': 'мы',\n",
       "  'будь': 'быть',\n",
       "  'сказано': 'сказать',\n",
       "  'приняло': 'принять',\n",
       "  'грустное': 'грустный',\n",
       "  'нем': 'немой',\n",
       "  'величества': 'величество',\n",
       "  'жалеют': 'жалеть',\n",
       "  'молча': 'молча',\n",
       "  'значительно': 'значительно',\n",
       "  'глядя': 'глядеть',\n",
       "  'ждала': 'ждать',\n",
       "  'ответа': 'ответ',\n",
       "  'поморщился': 'поморщиться',\n",
       "  'чтоб': 'чтоб',\n",
       "  'делал': 'делать',\n",
       "  'наконец': 'наконец',\n",
       "  'сделал': 'сделать',\n",
       "  'воспитания': 'воспитание',\n",
       "  'отец': 'отец',\n",
       "  'оба': 'оба',\n",
       "  'вышли': 'выйти',\n",
       "  'Ипполит': 'ипполит',\n",
       "  'крайней': 'крайний',\n",
       "  'мере': 'мера',\n",
       "  'покойный': 'покойный',\n",
       "  'дурак': 'дурак',\n",
       "  'а': 'а',\n",
       "  'Анатоль': 'анатоль',\n",
       "  'беспокойный': 'беспокойный',\n",
       "  'различие': 'различие',\n",
       "  'более': 'более',\n",
       "  'неестественно': 'неестественно',\n",
       "  'одушевленно': 'одушевлённый',\n",
       "  'обыкновенно': 'обыкновенно',\n",
       "  'этом': 'это',\n",
       "  'особенно': 'особенно',\n",
       "  'резко': 'резко',\n",
       "  'сложившихся': 'сложиться',\n",
       "  'около': 'около',\n",
       "  'рта': 'рот',\n",
       "  'морщинах': 'морщина',\n",
       "  'неожиданно-грубое': 'неожиданно-грубый',\n",
       "  'неприятное': 'неприятный',\n",
       "  'зачем': 'зачем',\n",
       "  'родятся': 'родиться',\n",
       "  'дети': 'ребёнок',\n",
       "  'были': 'быть',\n",
       "  'могла': 'мочь',\n",
       "  'упрекнуть': 'упрекнуть',\n",
       "  'задумчиво': 'задумчиво',\n",
       "  'поднимая': 'поднимать',\n",
       "  'Мои': 'мой',\n",
       "  'крест': 'крест',\n",
       "  'себе': 'себя',\n",
       "  'объясняю': 'объяснять',\n",
       "  'помолчал': 'помолчать',\n",
       "  'выражая': 'выражать',\n",
       "  'жестом': 'жест',\n",
       "  'покорность': 'покорность',\n",
       "  'жестокой': 'жестокий',\n",
       "  'судьбе': 'судьба',\n",
       "  'задумалась': 'задуматься',\n",
       "  'женить': 'женить',\n",
       "  'блудного': 'блудный',\n",
       "  'Говорят': 'говорить',\n",
       "  'старые': 'старый',\n",
       "  'девицы': 'девица',\n",
       "  'чувствую': 'чувствовать',\n",
       "  'собою': 'себя',\n",
       "  'этой': 'этот',\n",
       "  'слабости': 'слабость',\n",
       "  'несчастлива': 'несчастливый',\n",
       "  'отцом': 'отец',\n",
       "  'Болконская': 'болконский',\n",
       "  'светским': 'светский',\n",
       "  'людям': 'человек',\n",
       "  'быстротой': 'быстрота',\n",
       "  'соображения': 'соображение',\n",
       "  'памяти': 'память',\n",
       "  'показал': 'показать',\n",
       "  'движением': 'движение',\n",
       "  'головы': 'голова',\n",
       "  'принял': 'принять',\n",
       "  'соображению': 'соображение',\n",
       "  'эти': 'этот',\n",
       "  'сведения': 'сведение',\n",
       "  'Нет': 'нет',\n",
       "  'стоит': 'стоить',\n",
       "  'год': 'год',\n",
       "  'видимо': 'видимо',\n",
       "  'силах': 'сила',\n",
       "  'удерживать': 'удерживать',\n",
       "  'печальный': 'печальный',\n",
       "  'ход': 'ход',\n",
       "  'своих': 'свой',\n",
       "  'мыслей': 'мысль',\n",
       "  'пять': 'пять',\n",
       "  'если': 'если',\n",
       "  'пойдет': 'пойти',\n",
       "  'богата': 'богатый',\n",
       "  'княжна': 'княжна',\n",
       "  'Отец': 'отец',\n",
       "  'богат': 'богатый',\n",
       "  'скуп': 'скупой',\n",
       "  'живет': 'жить',\n",
       "  'деревне': 'деревня',\n",
       "  'известный': 'известный',\n",
       "  'Болконский': 'болконский',\n",
       "  'отставленный': 'отставить',\n",
       "  'покойном': 'покойный',\n",
       "  'императоре': 'император',\n",
       "  'прозванный': 'прозвать',\n",
       "  'прусским': 'прусский',\n",
       "  'королем': 'король',\n",
       "  'умный': 'умный',\n",
       "  'человек': 'человек',\n",
       "  'со': 'с',\n",
       "  'странностями': 'странность',\n",
       "  'тяжелый': 'тяжёлый',\n",
       "  'У': 'у',\n",
       "  'брат': 'брат',\n",
       "  'вот': 'вот',\n",
       "  'недавно': 'недавно',\n",
       "  'женился': 'жениться',\n",
       "  'Мейнен': 'мейнный',\n",
       "  'адъютант': 'адъютант',\n",
       "  'Кутузова': 'кутузов',\n",
       "  'взяв': 'взять',\n",
       "  'собеседницу': 'собеседница',\n",
       "  'пригибая': 'пригибать',\n",
       "  'почему-то': 'почему-то',\n",
       "  'книзу': 'книзу',\n",
       "  'вернейший': 'верный',\n",
       "  'староста': 'староста',\n",
       "  'донесенья': 'донесение',\n",
       "  'покой-ер-п': 'покой-ер-п',\n",
       "  'хорошей': 'хороший',\n",
       "  'фамилии': 'фамилия',\n",
       "  'Все': 'всё',\n",
       "  'нужно': 'нужно',\n",
       "  'свободными': 'свободный',\n",
       "  'фамильярными': 'фамильярный',\n",
       "  'грациозными': 'грациозный',\n",
       "  'движениями': 'движение',\n",
       "  'отличали': 'отличать',\n",
       "  'взял': 'взять',\n",
       "  'фрейлину': 'фрейлина',\n",
       "  'поцеловав': 'поцеловать',\n",
       "  'помахал': 'помахать',\n",
       "  'фрейлинскою': 'фрейлинский',\n",
       "  'рукой': 'рука',\n",
       "  'развалившись': 'развалиться',\n",
       "  'креслах': 'кресло',\n",
       "  'сторону': 'сторона',\n",
       "  'соображая': 'соображать',\n",
       "  'поговорю': 'поговорить',\n",
       "  'уладится': 'уладиться',\n",
       "  'Гостиная': 'гостиная',\n",
       "  'начала': 'начало',\n",
       "  'понемногу': 'понемногу',\n",
       "  'наполняться': 'наполняться',\n",
       "  'Приехала': 'приехать',\n",
       "  'высшая': 'высокий',\n",
       "  'знать': 'знать',\n",
       "  'Петербурга': 'петербург',\n",
       "  'люди': 'человек',\n",
       "  'самые': 'самый',\n",
       "  'разнородные': 'разнородный',\n",
       "  'возрастам': 'возраст',\n",
       "  'характерам': 'характер',\n",
       "  'одинаковые': 'одинаковый',\n",
       "  'обществу': 'общество',\n",
       "  'каком': 'какой',\n",
       "  'жили': 'жить',\n",
       "  'приехала': 'приехать',\n",
       "  'красавица': 'красавица',\n",
       "  'Элен': 'элен',\n",
       "  'заехавшая': 'заехать',\n",
       "  'ним': 'они',\n",
       "  'вместе': 'вместе',\n",
       "  'ехать': 'ехать',\n",
       "  'шифре': 'шифр',\n",
       "  'бальном': 'бальный',\n",
       "  'платье': 'платье',\n",
       "  'молодая': 'молодой',\n",
       "  'маленькая': 'маленький',\n",
       "  'княгиня': 'княгиня',\n",
       "  'прошлую': 'прошлый',\n",
       "  'зиму': 'зима',\n",
       "  'вышедшая': 'выйти',\n",
       "  'замуж': 'замуж',\n",
       "  'выезжавшая': 'выезжать',\n",
       "  'большой': 'большой',\n",
       "  'свет': 'свет',\n",
       "  'причине': 'причина',\n",
       "  'беременности': 'беременность',\n",
       "  'ездившая': 'ездить',\n",
       "  'небольшие': 'небольшой',\n",
       "  'вечера': 'вечер',\n",
       "  'Приехал': 'приехать',\n",
       "  'сын': 'сын',\n",
       "  'Мортемаром': 'мортемар',\n",
       "  'представил': 'представить',\n",
       "  'приехал': 'приехать',\n",
       "  'аббат': 'аббат',\n",
       "  'Морио': 'морио',\n",
       "  'многие': 'многие',\n",
       "  'другие': 'другой',\n",
       "  'видали': 'видать',\n",
       "  'знакомы': 'знакомый',\n",
       "  'приезжавшим': 'приезжать',\n",
       "  'гостям': 'гость',\n",
       "  'весьма': 'весьма',\n",
       "  'подводила': 'подводить',\n",
       "  'маленькой': 'маленький',\n",
       "  'старушке': 'старушка',\n",
       "  'высоких': 'высокий',\n",
       "  'бантах': 'бант',\n",
       "  'выплывшей': 'выплыть',\n",
       "  'комнаты': 'комната',\n",
       "  'скоро': 'скоро',\n",
       "  'стали': 'стать',\n",
       "  'приезжать': 'приезжать',\n",
       "  'гости': 'гость',\n",
       "  'называла': 'называть',\n",
       "  'имени': 'имя',\n",
       "  'медленно': 'медленно',\n",
       "  'переводя': 'переводить',\n",
       "  'гостя': 'гость',\n",
       "  'отходила': 'отходить',\n",
       "  'совершали': 'совершать',\n",
       "  'обряд': 'обряд',\n",
       "  'приветствования': 'приветствование',\n",
       "  'никому': 'никто',\n",
       "  'неизвестной': 'неизвестный',\n",
       "  'неинтересной': 'неинтересный',\n",
       "  'ненужной': 'ненужный',\n",
       "  'тетушки': 'тётушка',\n",
       "  'торжественным': 'торжественный',\n",
       "  'участием': 'участие',\n",
       "  'следила': 'следить',\n",
       "  'приветствиями': 'приветствие',\n",
       "  'молчаливо': 'молчаливо',\n",
       "  'одобряя': 'одобрять',\n",
       "  'каждому': 'каждый',\n",
       "  'одних': 'один',\n",
       "  'выражениях': 'выражение',\n",
       "  'здоровье': 'здоровье',\n",
       "  'своем': 'свой',\n",
       "  'слава': 'слава',\n",
       "  'Богу': 'бог',\n",
       "  'лучше': 'хороший',\n",
       "  'подходившие': 'подходить',\n",
       "  'поспешности': 'поспешность',\n",
       "  'чувством': 'чувство',\n",
       "  'облегчения': 'облегчение',\n",
       "  'исполненной': 'исполнить',\n",
       "  'тяжелой': 'тяжёлый',\n",
       "  'обязанности': 'обязанность',\n",
       "  'отходили': 'отходить',\n",
       "  'старушки': 'старушка',\n",
       "  'разу': 'раз',\n",
       "  'подойти': 'подойти',\n",
       "  'Молодая': 'молодой',\n",
       "  'работой': 'работа',\n",
       "  'золотом': 'золото',\n",
       "  'бархатном': 'бархатный',\n",
       "  'мешке': 'мешок',\n",
       "  'Ее': 'она',\n",
       "  'хорошенькая': 'хорошенький',\n",
       "  'чуть': 'чуть',\n",
       "  'черневшимися': 'чернеться',\n",
       "  'усиками': 'усик',\n",
       "  'верхняя': 'верхний',\n",
       "  'губка': 'губка',\n",
       "  'коротка': 'короткий',\n",
       "  'зубам': 'зуб',\n",
       "  'тем': 'тем',\n",
       "  'милее': 'милый',\n",
       "  'открывалась': 'открываться',\n",
       "  'вытягивалась': 'вытягиваться',\n",
       "  'опускалась': 'опускаться',\n",
       "  'нижнюю': 'нижний',\n",
       "  'бывает': 'бывать',\n",
       "  'вполне-привлекательных': 'вполне-привлекательный',\n",
       "  'женщин': 'женщина',\n",
       "  'недостаток': 'недостаток',\n",
       "  'короткость': 'короткость',\n",
       "  'губы': 'губа',\n",
       "  'полуоткрытый': 'полуоткрытый',\n",
       "  'рот': 'рот',\n",
       "  'казались': 'казаться',\n",
       "  'особенною': 'особенный',\n",
       "  'собственно': 'собственно',\n",
       "  'красотой': 'красота',\n",
       "  'Всем': 'весь',\n",
       "  'весело': 'весело',\n",
       "  'смотреть': 'смотреть',\n",
       "  'эту': 'этот',\n",
       "  'полную': 'полный',\n",
       "  'здоровья': 'здоровье',\n",
       "  'живости': 'живость',\n",
       "  'хорошенькую': 'хорошенький',\n",
       "  'будущую': 'будущий',\n",
       "  'мать': 'мать',\n",
       "  'легко': 'легко',\n",
       "  'переносившую': 'переносить',\n",
       "  'положение': 'положение',\n",
       "  'Старикам': 'старик',\n",
       "  'мрачным': 'мрачный',\n",
       "  'молодым': 'молодой',\n",
       "  'смотревшим': 'смотреть',\n",
       "  'казалось': 'казаться',\n",
       "  'сами': 'сам',\n",
       "  'делаются': 'делаться',\n",
       "  'похожи': 'похожий',\n",
       "  'побыв': 'побыть',\n",
       "  'поговорив': 'поговорить',\n",
       "  'времени': 'время',\n",
       "  'Кто': 'кто',\n",
       "  'видел': 'видеть',\n",
       "  'каждом': 'каждый',\n",
       "  'светлую': 'светлый',\n",
       "  'улыбочку': 'улыбочка',\n",
       "  'блестящие': 'блестящий',\n",
       "  'белые': 'белые',\n",
       "  'зубы': 'зуб',\n",
       "  'виднелись': 'виднеться',\n",
       "  'беспрестанно': 'беспрестанно',\n",
       "  'тот': 'тот',\n",
       "  'думал': 'думать',\n",
       "  'любезен': 'любезный',\n",
       "  'Маленькая': 'маленький',\n",
       "  'переваливаясь': 'переваливаться',\n",
       "  'маленькими': 'маленький',\n",
       "  'быстрыми': 'быстрый',\n",
       "  'шажками': 'шажок',\n",
       "  'обошла': 'обойти',\n",
       "  'стол': 'стол',\n",
       "  'рабочею': 'рабочий',\n",
       "  'сумочкою': 'сумочка',\n",
       "  'руке': 'рука',\n",
       "  'оправляя': 'оправлять',\n",
       "  'села': 'село',\n",
       "  'диван': 'диван',\n",
       "  'серебряного': 'серебряный',\n",
       "  'самовара': 'самовар',\n",
       "  'делала': 'делать',\n",
       "  'окружавших': 'окружать',\n",
       "  'развертывая': 'развёртывать',\n",
       "  'свой': 'свой',\n",
       "  'ридикюль': 'ридикюль',\n",
       "  'обращаясь': 'обращаться',\n",
       "  'ко': 'к',\n",
       "  'всем': 'весь',\n",
       "  'Смотрите': 'смотреть',\n",
       "  'обратилась': 'обратиться',\n",
       "  'хозяйке': 'хозяйка',\n",
       "  'развела': 'развести',\n",
       "  'руками': 'рука',\n",
       "  'показать': 'показать',\n",
       "  'кружевах': 'кружево',\n",
       "  'серенькое': 'серенький',\n",
       "  'изящное': 'изящный',\n",
       "  'немного': 'немного',\n",
       "  'ниже': 'ниже',\n",
       "  'грудей': 'грудь',\n",
       "  'опоясанное': 'опоясать',\n",
       "  'широкою': 'широкий',\n",
       "  'лентой': 'лента',\n",
       "  'отвечала': 'отвечать',\n",
       "  'генералу': 'генерал',\n",
       "  'Василию': 'василий',\n",
       "  'дожидаясь': 'дожидаться',\n",
       "  'дочери': 'дочь',\n",
       "  'красивой': 'красивый',\n",
       "  'тихо': 'тихо',\n",
       "  'Вскоре': 'вскоре',\n",
       "  'княгини': 'княгиня',\n",
       "  'вошел': 'войти',\n",
       "  'массивный': 'массивный',\n",
       "  'толстый': 'толстый',\n",
       "  'молодой': 'молодой',\n",
       "  'стриженою': 'стриженый',\n",
       "  'головой': 'голова',\n",
       "  'очках': 'очки',\n",
       "  'светлых': 'светлый',\n",
       "  'панталонах': 'панталоны',\n",
       "  'тогдашней': 'тогдашний',\n",
       "  'моде': 'мода',\n",
       "  'высоким': 'высокий',\n",
       "  'жабо': 'жабо',\n",
       "  'коричневом': 'коричневый',\n",
       "  'фраке': 'фрак',\n",
       "  'Этот': 'этот',\n",
       "  'незаконный': 'незаконный',\n",
       "  'знаменитого': 'знаменитый',\n",
       "  'Екатерининского': 'екатерининский',\n",
       "  'вельможи': 'вельможа',\n",
       "  'графа': 'граф',\n",
       "  'Безухого': 'безухий',\n",
       "  'умиравшего': 'умирать',\n",
       "  'Москве': 'москва',\n",
       "  'нигде': 'нигде',\n",
       "  'служил': 'служить',\n",
       "  'границы': 'граница',\n",
       "  'где': 'где',\n",
       "  'воспитывался': 'воспитываться',\n",
       "  'первый': 'первый',\n",
       "  'обществе': 'общество',\n",
       "  'приветствовала': 'приветствовать',\n",
       "  'поклоном': 'поклон',\n",
       "  'относящимся': 'относиться',\n",
       "  'самой': 'сам',\n",
       "  ...},\n",
       " '_FasterMorphology2__dictionary': {'лев': 0,\n",
       "  'николаевич': 1,\n",
       "  'толстой': 2,\n",
       "  'война': 3,\n",
       "  'и': 4,\n",
       "  'мир': 5,\n",
       "  'тот': 6,\n",
       "  'часть': 7,\n",
       "  'первый': 8,\n",
       "  'быть': 9,\n",
       "  'поместье': 10,\n",
       "  'мой': 11,\n",
       "  'верный': 12,\n",
       "  'раб': 13,\n",
       "  'ну': 14,\n",
       "  'здравствуйте': 15,\n",
       "  'садиться': 16,\n",
       "  'рассказывать': 17,\n",
       "  'так': 18,\n",
       "  'говорить': 19,\n",
       "  'в': 20,\n",
       "  'июль': 21,\n",
       "  'год': 22,\n",
       "  'известный': 23,\n",
       "  'анна': 24,\n",
       "  'павлович': 25,\n",
       "  'шерер': 26,\n",
       "  'фрейлина': 27,\n",
       "  'приблизить': 28,\n",
       "  'императрица': 29,\n",
       "  'мария': 30,\n",
       "  'феодоровный': 31,\n",
       "  'встречать': 32,\n",
       "  'важный': 33,\n",
       "  'чиновный': 34,\n",
       "  'князь': 35,\n",
       "  'василий': 36,\n",
       "  'приехать': 37,\n",
       "  'на': 38,\n",
       "  'она': 39,\n",
       "  'вечер': 40,\n",
       "  'кашлять': 41,\n",
       "  'несколько': 42,\n",
       "  'день': 43,\n",
       "  'у': 44,\n",
       "  'грипп': 45,\n",
       "  'как': 46,\n",
       "  'тогда': 47,\n",
       "  'новый': 48,\n",
       "  'слово': 49,\n",
       "  'употребляться': 50,\n",
       "  'только': 51,\n",
       "  'редкий': 52,\n",
       "  'записочка': 53,\n",
       "  'разослать': 54,\n",
       "  'утром': 55,\n",
       "  'с': 56,\n",
       "  'красный': 57,\n",
       "  'лакей': 58,\n",
       "  'написать': 59,\n",
       "  'без': 60,\n",
       "  'различие': 61,\n",
       "  'весь': 62,\n",
       "  'или': 63,\n",
       "  'отвечать': 64,\n",
       "  'нисколько': 65,\n",
       "  'не': 66,\n",
       "  'смутиться': 67,\n",
       "  'такой': 68,\n",
       "  'встреча': 69,\n",
       "  'войти': 70,\n",
       "  'придворный': 71,\n",
       "  'шитый': 72,\n",
       "  'мундир': 73,\n",
       "  'чулок': 74,\n",
       "  'башмак': 75,\n",
       "  'при': 76,\n",
       "  'звезда': 77,\n",
       "  'светлый': 78,\n",
       "  'выражение': 79,\n",
       "  'плоский': 80,\n",
       "  'лицо': 81,\n",
       "  'он': 82,\n",
       "  'изысканный': 83,\n",
       "  'французский': 84,\n",
       "  'язык': 85,\n",
       "  'который': 86,\n",
       "  'но': 87,\n",
       "  'думать': 88,\n",
       "  'наш': 89,\n",
       "  'дед': 90,\n",
       "  'тихий': 91,\n",
       "  'покровительственный': 92,\n",
       "  'интонация': 93,\n",
       "  'свойственный': 94,\n",
       "  'состаревшийся': 95,\n",
       "  'свет': 96,\n",
       "  'двор': 97,\n",
       "  'значительный': 98,\n",
       "  'человек': 99,\n",
       "  'подойти': 100,\n",
       "  'к': 101,\n",
       "  'анне': 102,\n",
       "  'поцеловать': 103,\n",
       "  'рука': 104,\n",
       "  'подставить': 105,\n",
       "  'свой': 106,\n",
       "  'надушить': 107,\n",
       "  'сиять': 108,\n",
       "  'лысина': 109,\n",
       "  'покойно': 110,\n",
       "  'усесться': 111,\n",
       "  'диван': 112,\n",
       "  'успокоить': 113,\n",
       "  'друг': 114,\n",
       "  'сказать': 115,\n",
       "  'изменять': 116,\n",
       "  'голос': 117,\n",
       "  'тон': 118,\n",
       "  'из-за': 119,\n",
       "  'приличие': 120,\n",
       "  'участие': 121,\n",
       "  'просвечивать': 122,\n",
       "  'равнодушие': 123,\n",
       "  'даже': 124,\n",
       "  'насмешка': 125,\n",
       "  'можно': 126,\n",
       "  'здоровый': 127,\n",
       "  'когда': 128,\n",
       "  'нравственно': 129,\n",
       "  'страдать': 130,\n",
       "  'разве': 131,\n",
       "  'оставаться': 132,\n",
       "  'спокойный': 133,\n",
       "  'время': 134,\n",
       "  'есть': 135,\n",
       "  'чувство': 136,\n",
       "  'вы': 137,\n",
       "  'я': 138,\n",
       "  'надеяться': 139,\n",
       "  'а': 140,\n",
       "  'праздник': 141,\n",
       "  'английский': 142,\n",
       "  'посланник': 143,\n",
       "  'нынче': 144,\n",
       "  'середа': 145,\n",
       "  'надо': 146,\n",
       "  'показаться': 147,\n",
       "  'там': 148,\n",
       "  'дочь': 149,\n",
       "  'заехать': 150,\n",
       "  'за': 151,\n",
       "  'повезти': 152,\n",
       "  'что': 153,\n",
       "  'нынешний': 154,\n",
       "  'отменный': 155,\n",
       "  'ежели': 156,\n",
       "  'бы': 157,\n",
       "  'знать': 158,\n",
       "  'это': 159,\n",
       "  'хотеть': 160,\n",
       "  'отменить': 161,\n",
       "  'по': 162,\n",
       "  'привычка': 163,\n",
       "  'завести': 164,\n",
       "  'часы': 165,\n",
       "  'вещь': 166,\n",
       "  'чтобы': 167,\n",
       "  'верить': 168,\n",
       "  'холодный': 169,\n",
       "  'скучать': 170,\n",
       "  'всегда': 171,\n",
       "  'лениво': 172,\n",
       "  'актёр': 173,\n",
       "  'роль': 174,\n",
       "  'старый': 175,\n",
       "  'пиес': 176,\n",
       "  'напротив': 177,\n",
       "  'несмотря': 178,\n",
       "  'сорок': 179,\n",
       "  'преисполнить': 180,\n",
       "  'оживление': 181,\n",
       "  'порыв': 182,\n",
       "  'энтузиастка': 183,\n",
       "  'сделаться': 184,\n",
       "  'общественный': 185,\n",
       "  'положение': 186,\n",
       "  'иногда': 187,\n",
       "  'хотеться': 188,\n",
       "  'обмануть': 189,\n",
       "  'ожидание': 190,\n",
       "  'делаться': 191,\n",
       "  'сдержать': 192,\n",
       "  'улыбка': 193,\n",
       "  'играть': 194,\n",
       "  'постоянно': 195,\n",
       "  'хотя': 196,\n",
       "  'идти': 197,\n",
       "  'отживший': 198,\n",
       "  'черта': 199,\n",
       "  'выражать': 200,\n",
       "  'избаловать': 201,\n",
       "  'ребёнок': 202,\n",
       "  'постоянный': 203,\n",
       "  'сознание': 204,\n",
       "  'милый': 205,\n",
       "  'недостаток': 206,\n",
       "  'от': 207,\n",
       "  'мочь': 208,\n",
       "  'находить': 209,\n",
       "  'нужный': 210,\n",
       "  'исправляться': 211,\n",
       "  'середина': 212,\n",
       "  'разговор': 213,\n",
       "  'про': 214,\n",
       "  'политический': 215,\n",
       "  'действие': 216,\n",
       "  'разгорячиться': 217,\n",
       "  'ах': 218,\n",
       "  'австрия': 219,\n",
       "  'ничего': 220,\n",
       "  'понимать': 221,\n",
       "  'никогда': 222,\n",
       "  'предавать': 223,\n",
       "  'мы': 224,\n",
       "  'россия': 225,\n",
       "  'один': 226,\n",
       "  'должный': 227,\n",
       "  'спасительница': 228,\n",
       "  'европа': 229,\n",
       "  'благодетель': 230,\n",
       "  'высокий': 231,\n",
       "  'призвание': 232,\n",
       "  'вот': 233,\n",
       "  'добрый': 234,\n",
       "  'чудной': 235,\n",
       "  'государь': 236,\n",
       "  'предстоять': 237,\n",
       "  'великий': 238,\n",
       "  'добродетельный': 239,\n",
       "  'хороший': 240,\n",
       "  'бог': 241,\n",
       "  'оставить': 242,\n",
       "  'исполнить': 243,\n",
       "  'задавить': 244,\n",
       "  'гидра': 245,\n",
       "  'революция': 246,\n",
       "  'теперь': 247,\n",
       "  'ещё': 248,\n",
       "  'ужасный': 249,\n",
       "  'убийца': 250,\n",
       "  'злодей': 251,\n",
       "  'искупить': 252,\n",
       "  'кровь': 253,\n",
       "  'праведник': 254,\n",
       "  'кто': 255,\n",
       "  'спрашивать': 256,\n",
       "  'англия': 257,\n",
       "  'коммерческий': 258,\n",
       "  'дух': 259,\n",
       "  'понять': 260,\n",
       "  'высота': 261,\n",
       "  'душа': 262,\n",
       "  'император': 263,\n",
       "  'александр': 264,\n",
       "  'отказаться': 265,\n",
       "  'очистить': 266,\n",
       "  'мальта': 267,\n",
       "  'видеть': 268,\n",
       "  'искать': 269,\n",
       "  'задний': 270,\n",
       "  'мысль': 271,\n",
       "  'они': 272,\n",
       "  'новосильцов': 273,\n",
       "  'самоотвержение': 274,\n",
       "  'для': 275,\n",
       "  'себя': 276,\n",
       "  'всё': 277,\n",
       "  'благо': 278,\n",
       "  'обещать': 279,\n",
       "  'пруссия': 280,\n",
       "  'уж': 281,\n",
       "  'объявить': 282,\n",
       "  'бонапарт': 283,\n",
       "  'непобедимый': 284,\n",
       "  'против': 285,\n",
       "  'ни': 286,\n",
       "  'гарденберг': 287,\n",
       "  'гаугвица': 288,\n",
       "  'судьба': 289,\n",
       "  'спасти': 290,\n",
       "  'вдруг': 291,\n",
       "  'остановиться': 292,\n",
       "  'над': 293,\n",
       "  'горячность': 294,\n",
       "  'улыбаться': 295,\n",
       "  'послать': 296,\n",
       "  'вместо': 297,\n",
       "  'винценгерод': 298,\n",
       "  'взять': 299,\n",
       "  'приступ': 300,\n",
       "  'согласие': 301,\n",
       "  'прусский': 302,\n",
       "  'король': 303,\n",
       "  'красноречивый': 304,\n",
       "  'дать': 305,\n",
       "  'чай': 306,\n",
       "  'сейчас': 307,\n",
       "  'прибавить': 308,\n",
       "  'опять': 309,\n",
       "  'успокоиваться': 310,\n",
       "  'два': 311,\n",
       "  'очень': 312,\n",
       "  'интересный': 313,\n",
       "  'из': 314,\n",
       "  'фамилия': 315,\n",
       "  'франция': 316,\n",
       "  'эмигрант': 317,\n",
       "  'настоящий': 318,\n",
       "  'потом': 319,\n",
       "  'этот': 320,\n",
       "  'глубокий': 321,\n",
       "  'ум': 322,\n",
       "  'принять': 323,\n",
       "  'рад': 324,\n",
       "  'будто': 325,\n",
       "  'вспомнить': 326,\n",
       "  'что-то': 327,\n",
       "  'особенно-небрежно': 328,\n",
       "  'то': 329,\n",
       "  'о': 330,\n",
       "  'чем': 331,\n",
       "  'главный': 332,\n",
       "  'цель': 333,\n",
       "  'посещение': 334,\n",
       "  'правда': 335,\n",
       "  'желать': 336,\n",
       "  'назначение': 337,\n",
       "  'барон': 338,\n",
       "  'функа': 339,\n",
       "  'секретарь': 340,\n",
       "  'вена': 341,\n",
       "  'определить': 342,\n",
       "  'сын': 343,\n",
       "  'место': 344,\n",
       "  'через': 345,\n",
       "  'феодорович': 346,\n",
       "  'стараться': 347,\n",
       "  'доставить': 348,\n",
       "  'почти': 349,\n",
       "  'закрыть': 350,\n",
       "  'глаз': 351,\n",
       "  'знак': 352,\n",
       "  'другой': 353,\n",
       "  'судить': 354,\n",
       "  'угодный': 355,\n",
       "  'нравиться': 356,\n",
       "  'грустный': 357,\n",
       "  'сухой': 358,\n",
       "  'назвать': 359,\n",
       "  'представить': 360,\n",
       "  'искренний': 361,\n",
       "  'преданность': 362,\n",
       "  'уважение': 363,\n",
       "  'соединить': 364,\n",
       "  'грусть': 365,\n",
       "  'бывало': 366,\n",
       "  'каждый': 367,\n",
       "  'раз': 368,\n",
       "  'упоминать': 369,\n",
       "  'покровительница': 370,\n",
       "  'величество': 371,\n",
       "  'изволить': 372,\n",
       "  'оказать': 373,\n",
       "  'взгляд': 374,\n",
       "  'подёрнуться': 375,\n",
       "  'равнодушно': 376,\n",
       "  'замолкнуть': 377,\n",
       "  'женский': 378,\n",
       "  'ловкость': 379,\n",
       "  'быстрота': 380,\n",
       "  'такт': 381,\n",
       "  'захотеть': 382,\n",
       "  'щелконуть': 383,\n",
       "  'дерзнуть': 384,\n",
       "  'отозваться': 385,\n",
       "  'рекомендовать': 386,\n",
       "  'же': 387,\n",
       "  'утешить': 388,\n",
       "  'ли': 389,\n",
       "  'ваш': 390,\n",
       "  'пора': 391,\n",
       "  'выезжать': 392,\n",
       "  'наклониться': 393,\n",
       "  'признательность': 394,\n",
       "  'часто': 395,\n",
       "  'продолжать': 396,\n",
       "  'после': 397,\n",
       "  'минутный': 398,\n",
       "  'молчание': 399,\n",
       "  'подвигаться': 400,\n",
       "  'ласково': 401,\n",
       "  'выказывать': 402,\n",
       "  'светский': 403,\n",
       "  'конченый': 404,\n",
       "  'начинаться': 405,\n",
       "  'задушевный': 406,\n",
       "  'несправедливый': 407,\n",
       "  'распределяться': 408,\n",
       "  'счастие': 409,\n",
       "  'жизнь': 410,\n",
       "  'славный': 411,\n",
       "  'исключая': 412,\n",
       "  'анатоль': 413,\n",
       "  'меньшой': 414,\n",
       "  'любить': 415,\n",
       "  'вставить': 416,\n",
       "  'безапелляционно': 417,\n",
       "  'приподнять': 418,\n",
       "  'бровь': 419,\n",
       "  'прелестный': 420,\n",
       "  'право': 421,\n",
       "  'менее': 422,\n",
       "  'ценить': 423,\n",
       "  'потому': 424,\n",
       "  'стоить': 425,\n",
       "  'улыбнуться': 426,\n",
       "  'восторженный': 427,\n",
       "  'перестать': 428,\n",
       "  'шутить': 429,\n",
       "  'серьёзно': 430,\n",
       "  'поговорить': 431,\n",
       "  'недовольный': 432,\n",
       "  'малый': 433,\n",
       "  'между': 434,\n",
       "  'немой': 435,\n",
       "  'жалеть': 436,\n",
       "  'молча': 437,\n",
       "  'значительно': 438,\n",
       "  'глядеть': 439,\n",
       "  'ждать': 440,\n",
       "  'ответ': 441,\n",
       "  'поморщиться': 442,\n",
       "  'чтоб': 443,\n",
       "  'делать': 444,\n",
       "  'наконец': 445,\n",
       "  'сделать': 446,\n",
       "  'воспитание': 447,\n",
       "  'отец': 448,\n",
       "  'оба': 449,\n",
       "  'выйти': 450,\n",
       "  'ипполит': 451,\n",
       "  'крайний': 452,\n",
       "  'мера': 453,\n",
       "  'покойный': 454,\n",
       "  'дурак': 455,\n",
       "  'беспокойный': 456,\n",
       "  'более': 457,\n",
       "  'неестественно': 458,\n",
       "  'одушевлённый': 459,\n",
       "  'обыкновенно': 460,\n",
       "  'особенно': 461,\n",
       "  'резко': 462,\n",
       "  'сложиться': 463,\n",
       "  'около': 464,\n",
       "  'рот': 465,\n",
       "  'морщина': 466,\n",
       "  'неожиданно-грубый': 467,\n",
       "  'неприятный': 468,\n",
       "  'зачем': 469,\n",
       "  'родиться': 470,\n",
       "  'упрекнуть': 471,\n",
       "  'задумчиво': 472,\n",
       "  'поднимать': 473,\n",
       "  'крест': 474,\n",
       "  'объяснять': 475,\n",
       "  'помолчать': 476,\n",
       "  'жест': 477,\n",
       "  'покорность': 478,\n",
       "  'жестокий': 479,\n",
       "  'задуматься': 480,\n",
       "  'женить': 481,\n",
       "  'блудный': 482,\n",
       "  'девица': 483,\n",
       "  'чувствовать': 484,\n",
       "  'слабость': 485,\n",
       "  'несчастливый': 486,\n",
       "  'болконский': 487,\n",
       "  'соображение': 488,\n",
       "  'память': 489,\n",
       "  'показать': 490,\n",
       "  'движение': 491,\n",
       "  'голова': 492,\n",
       "  'сведение': 493,\n",
       "  'нет': 494,\n",
       "  'видимо': 495,\n",
       "  'сила': 496,\n",
       "  'удерживать': 497,\n",
       "  'печальный': 498,\n",
       "  'ход': 499,\n",
       "  'пять': 500,\n",
       "  'если': 501,\n",
       "  'пойти': 502,\n",
       "  'богатый': 503,\n",
       "  'княжна': 504,\n",
       "  'скупой': 505,\n",
       "  'жить': 506,\n",
       "  'деревня': 507,\n",
       "  'отставить': 508,\n",
       "  'прозвать': 509,\n",
       "  'умный': 510,\n",
       "  'странность': 511,\n",
       "  'тяжёлый': 512,\n",
       "  'брат': 513,\n",
       "  'недавно': 514,\n",
       "  'жениться': 515,\n",
       "  'мейнный': 516,\n",
       "  'адъютант': 517,\n",
       "  'кутузов': 518,\n",
       "  'собеседница': 519,\n",
       "  'пригибать': 520,\n",
       "  'почему-то': 521,\n",
       "  'книзу': 522,\n",
       "  'староста': 523,\n",
       "  'донесение': 524,\n",
       "  'покой-ер-п': 525,\n",
       "  'нужно': 526,\n",
       "  'свободный': 527,\n",
       "  'фамильярный': 528,\n",
       "  'грациозный': 529,\n",
       "  'отличать': 530,\n",
       "  'помахать': 531,\n",
       "  'фрейлинский': 532,\n",
       "  'развалиться': 533,\n",
       "  'кресло': 534,\n",
       "  'сторона': 535,\n",
       "  'соображать': 536,\n",
       "  'уладиться': 537,\n",
       "  'гостиная': 538,\n",
       "  'начало': 539,\n",
       "  'понемногу': 540,\n",
       "  'наполняться': 541,\n",
       "  'петербург': 542,\n",
       "  'самый': 543,\n",
       "  'разнородный': 544,\n",
       "  'возраст': 545,\n",
       "  'характер': 546,\n",
       "  'одинаковый': 547,\n",
       "  'общество': 548,\n",
       "  'какой': 549,\n",
       "  'красавица': 550,\n",
       "  'элен': 551,\n",
       "  'вместе': 552,\n",
       "  'ехать': 553,\n",
       "  'шифр': 554,\n",
       "  'бальный': 555,\n",
       "  'платье': 556,\n",
       "  'молодой': 557,\n",
       "  'маленький': 558,\n",
       "  'княгиня': 559,\n",
       "  'прошлый': 560,\n",
       "  'зима': 561,\n",
       "  'замуж': 562,\n",
       "  'большой': 563,\n",
       "  'причина': 564,\n",
       "  'беременность': 565,\n",
       "  'ездить': 566,\n",
       "  'небольшой': 567,\n",
       "  'мортемар': 568,\n",
       "  'аббат': 569,\n",
       "  'морио': 570,\n",
       "  'многие': 571,\n",
       "  'видать': 572,\n",
       "  'знакомый': 573,\n",
       "  'приезжать': 574,\n",
       "  'гость': 575,\n",
       "  'весьма': 576,\n",
       "  'подводить': 577,\n",
       "  'старушка': 578,\n",
       "  'бант': 579,\n",
       "  'выплыть': 580,\n",
       "  'комната': 581,\n",
       "  'скоро': 582,\n",
       "  'стать': 583,\n",
       "  'называть': 584,\n",
       "  'имя': 585,\n",
       "  'медленно': 586,\n",
       "  'переводить': 587,\n",
       "  'отходить': 588,\n",
       "  'совершать': 589,\n",
       "  'обряд': 590,\n",
       "  'приветствование': 591,\n",
       "  'никто': 592,\n",
       "  'неизвестный': 593,\n",
       "  'неинтересный': 594,\n",
       "  'ненужный': 595,\n",
       "  'тётушка': 596,\n",
       "  'торжественный': 597,\n",
       "  'следить': 598,\n",
       "  'приветствие': 599,\n",
       "  'молчаливо': 600,\n",
       "  'одобрять': 601,\n",
       "  'здоровье': 602,\n",
       "  'слава': 603,\n",
       "  'подходить': 604,\n",
       "  'поспешность': 605,\n",
       "  'облегчение': 606,\n",
       "  'обязанность': 607,\n",
       "  'работа': 608,\n",
       "  'золото': 609,\n",
       "  'бархатный': 610,\n",
       "  'мешок': 611,\n",
       "  'хорошенький': 612,\n",
       "  'чуть': 613,\n",
       "  'чернеться': 614,\n",
       "  'усик': 615,\n",
       "  'верхний': 616,\n",
       "  'губка': 617,\n",
       "  'короткий': 618,\n",
       "  'зуб': 619,\n",
       "  'тем': 620,\n",
       "  'открываться': 621,\n",
       "  'вытягиваться': 622,\n",
       "  'опускаться': 623,\n",
       "  'нижний': 624,\n",
       "  'бывать': 625,\n",
       "  'вполне-привлекательный': 626,\n",
       "  'женщина': 627,\n",
       "  'короткость': 628,\n",
       "  'губа': 629,\n",
       "  'полуоткрытый': 630,\n",
       "  'казаться': 631,\n",
       "  'особенный': 632,\n",
       "  'собственно': 633,\n",
       "  'красота': 634,\n",
       "  'весело': 635,\n",
       "  'смотреть': 636,\n",
       "  'полный': 637,\n",
       "  'живость': 638,\n",
       "  'будущий': 639,\n",
       "  'мать': 640,\n",
       "  'легко': 641,\n",
       "  'переносить': 642,\n",
       "  'старик': 643,\n",
       "  'мрачный': 644,\n",
       "  'сам': 645,\n",
       "  'похожий': 646,\n",
       "  'побыть': 647,\n",
       "  'улыбочка': 648,\n",
       "  'блестящий': 649,\n",
       "  'белые': 650,\n",
       "  'виднеться': 651,\n",
       "  'беспрестанно': 652,\n",
       "  'любезный': 653,\n",
       "  'переваливаться': 654,\n",
       "  'быстрый': 655,\n",
       "  'шажок': 656,\n",
       "  'обойти': 657,\n",
       "  'стол': 658,\n",
       "  'рабочий': 659,\n",
       "  'сумочка': 660,\n",
       "  'оправлять': 661,\n",
       "  'село': 662,\n",
       "  'серебряный': 663,\n",
       "  'самовар': 664,\n",
       "  'окружать': 665,\n",
       "  'развёртывать': 666,\n",
       "  'ридикюль': 667,\n",
       "  'обращаться': 668,\n",
       "  'обратиться': 669,\n",
       "  'хозяйка': 670,\n",
       "  'развести': 671,\n",
       "  'кружево': 672,\n",
       "  'серенький': 673,\n",
       "  'изящный': 674,\n",
       "  'немного': 675,\n",
       "  'ниже': 676,\n",
       "  'грудь': 677,\n",
       "  'опоясать': 678,\n",
       "  'широкий': 679,\n",
       "  'лента': 680,\n",
       "  'генерал': 681,\n",
       "  'дожидаться': 682,\n",
       "  'красивый': 683,\n",
       "  'тихо': 684,\n",
       "  'вскоре': 685,\n",
       "  'массивный': 686,\n",
       "  'толстый': 687,\n",
       "  'стриженый': 688,\n",
       "  'очки': 689,\n",
       "  'панталоны': 690,\n",
       "  'тогдашний': 691,\n",
       "  'мода': 692,\n",
       "  'жабо': 693,\n",
       "  'коричневый': 694,\n",
       "  'фрак': 695,\n",
       "  'незаконный': 696,\n",
       "  'знаменитый': 697,\n",
       "  'екатерининский': 698,\n",
       "  'вельможа': 699,\n",
       "  'граф': 700,\n",
       "  'безухий': 701,\n",
       "  'умирать': 702,\n",
       "  'москва': 703,\n",
       "  'нигде': 704,\n",
       "  'служить': 705,\n",
       "  'граница': 706,\n",
       "  'где': 707,\n",
       "  'воспитываться': 708,\n",
       "  'приветствовать': 709,\n",
       "  'поклон': 710,\n",
       "  'относиться': 711,\n",
       "  'низкий': 712,\n",
       "  'иерархия': 713,\n",
       "  'салон': 714,\n",
       "  'сорт': 715,\n",
       "  'вид': 716,\n",
       "  'пьер': 717,\n",
       "  'изобразиться': 718,\n",
       "  'беспокойство': 719,\n",
       "  'страх': 720,\n",
       "  'подобный': 721,\n",
       "  'выражаться': 722,\n",
       "  'что-нибудь': 723,\n",
       "  'слишком': 724,\n",
       "  'огромный': 725,\n",
       "  'несвойственный': 726,\n",
       "  'действительно': 727,\n",
       "  'мужчина': 728,\n",
       "  'робкий': 729,\n",
       "  'наблюдательный': 730,\n",
       "  'естественный': 731,\n",
       "  'испуганно': 732,\n",
       "  'переглядываться': 733,\n",
       "  'пробурлить': 734,\n",
       "  'непонятный': 735,\n",
       "  'отыскивать': 736,\n",
       "  'радостно': 737,\n",
       "  'кланяться': 738,\n",
       "  'близкий': 739,\n",
       "  'напрасный': 740,\n",
       "  'дослушать': 741,\n",
       "  'речь': 742,\n",
       "  'отойти': 743,\n",
       "  'остановить': 744,\n",
       "  'да': 745,\n",
       "  'слышать': 746,\n",
       "  'план': 747,\n",
       "  'вечный': 748,\n",
       "  'интересно': 749,\n",
       "  'едва': 750,\n",
       "  'возможно': 751,\n",
       "  'вновь': 752,\n",
       "  'занятие': 753,\n",
       "  'дом': 754,\n",
       "  'обратный': 755,\n",
       "  'неучтивость': 756,\n",
       "  'прежде': 757,\n",
       "  'уйти': 758,\n",
       "  'нагнуть': 759,\n",
       "  'расставить': 760,\n",
       "  'больший': 761,\n",
       "  'нога': 762,\n",
       "  'доказывать': 763,\n",
       "  'почему': 764,\n",
       "  'полагать': 765,\n",
       "  'химера': 766,\n",
       "  'отделаться': 767,\n",
       "  'уметь': 768,\n",
       "  'возвратиться': 769,\n",
       "  'прислушиваться': 770,\n",
       "  'приглядываться': 771,\n",
       "  'готовый': 772,\n",
       "  'подать': 773,\n",
       "  'помощь': 774,\n",
       "  'пункт': 775,\n",
       "  'ослабевать': 776,\n",
       "  'хозяин': 777,\n",
       "  'прядильный': 778,\n",
       "  'мастерская': 779,\n",
       "  'посадить': 780,\n",
       "  'работник': 781,\n",
       "  'прохаживаться': 782,\n",
       "  'заведение': 783,\n",
       "  'замечать': 784,\n",
       "  'неподвижность': 785,\n",
       "  'непривычный': 786,\n",
       "  'скрипеть': 787,\n",
       "  'громкий': 788,\n",
       "  'звук': 789,\n",
       "  'веретено': 790,\n",
       "  'торопливо': 791,\n",
       "  'сдерживать': 792,\n",
       "  'пускать': 793,\n",
       "  'надлежащий': 794,\n",
       "  'много': 795,\n",
       "  'кружка': 796,\n",
       "  'перемещение': 797,\n",
       "  'заводила': 798,\n",
       "  'равномерный': 799,\n",
       "  'приличный': 800,\n",
       "  'разговорный': 801,\n",
       "  'машина': 802,\n",
       "  'среди': 803,\n",
       "  'забота': 804,\n",
       "  'видный': 805,\n",
       "  'заботливо': 806,\n",
       "  'поглядывать': 807,\n",
       "  'послушать': 808,\n",
       "  'говориться': 809,\n",
       "  'мортемара': 810,\n",
       "  'воспитанный': 811,\n",
       "  'тут': 812,\n",
       "  'собрать': 813,\n",
       "  'интеллигенция': 814,\n",
       "  'игрушечный': 815,\n",
       "  'лавка': 816,\n",
       "  'разбегаться': 817,\n",
       "  'бояться': 818,\n",
       "  'пропустить': 819,\n",
       "  'услыхать': 820,\n",
       "  'уверенный': 821,\n",
       "  'собранный': 822,\n",
       "  'здесь': 823,\n",
       "  'ожидать': 824,\n",
       "  'случай': 825,\n",
       "  'высказать': 826,\n",
       "  'пустить': 827,\n",
       "  'разный': 828,\n",
       "  'равномерно': 829,\n",
       "  'умолкать': 830,\n",
       "  'шуметь': 831,\n",
       "  'кроме': 832,\n",
       "  'сидеть': 833,\n",
       "  'пожилой': 834,\n",
       "  'дама': 835,\n",
       "  'исплакать': 836,\n",
       "  'худой': 837,\n",
       "  'чужой': 838,\n",
       "  'разбиться': 839,\n",
       "  'три': 840,\n",
       "  'мужской': 841,\n",
       "  'центр': 842,\n",
       "  'красавица-княжна': 843,\n",
       "  'румяный': 844,\n",
       "  'молодость': 845,\n",
       "  'третий': 846,\n",
       "  'виконт': 847,\n",
       "  'миловидный': 848,\n",
       "  'мягкий': 849,\n",
       "  'приём': 850,\n",
       "  'очевидный': 851,\n",
       "  'считать': 852,\n",
       "  'знаменитость': 853,\n",
       "  'благовоспитанность': 854,\n",
       "  'скромно': 855,\n",
       "  'предоставлять': 856,\n",
       "  'пользоваться': 857,\n",
       "  'находиться': 858,\n",
       "  'угощать': 859,\n",
       "  'метрд': 860,\n",
       "  'отель': 861,\n",
       "  'подавать': 862,\n",
       "  'нечто': 863,\n",
       "  'сверхъестественно-прекрасный': 864,\n",
       "  'кусок': 865,\n",
       "  'говядина': 866,\n",
       "  'захотеться': 867,\n",
       "  'увидать': 868,\n",
       "  'грязный': 869,\n",
       "  'кухня': 870,\n",
       "  'сервировать': 871,\n",
       "  'сначала': 872,\n",
       "  'сверхъестественный': 873,\n",
       "  'утончить': 874,\n",
       "  'заговорить': 875,\n",
       "  'тотчас': 876,\n",
       "  'убиение': 877,\n",
       "  'герцог': 878,\n",
       "  'энгиенский': 879,\n",
       "  'погибнуть': 880,\n",
       "  'великодушие': 881,\n",
       "  'озлобление': 882,\n",
       "  'радость': 883,\n",
       "  'отзываться': 884,\n",
       "  'фраза': 885,\n",
       "  'поклониться': 886,\n",
       "  'учтивый': 887,\n",
       "  'круг': 888,\n",
       "  'пригласить': 889,\n",
       "  'слушать': 890,\n",
       "  'рассказ': 891,\n",
       "  'шепнуть': 892,\n",
       "  'проговорить': 893,\n",
       "  'выгодный': 894,\n",
       "  'ростбиф': 895,\n",
       "  'горячее': 896,\n",
       "  'блюдо': 897,\n",
       "  'посыпать': 898,\n",
       "  'зелень': 899,\n",
       "  'уже': 900,\n",
       "  'начать': 901,\n",
       "  'тонко': 902,\n",
       "  'переходить': 903,\n",
       "  'сюда': 904,\n",
       "  'поодаль': 905,\n",
       "  'составлять': 906,\n",
       "  'подняться': 907,\n",
       "  'той': 908,\n",
       "  'неизменяться': 909,\n",
       "  'вполне': 910,\n",
       "  'котора': 911,\n",
       "  'гостиный': 912,\n",
       "  'слегка': 913,\n",
       "  'бела': 914,\n",
       "  'роба': 915,\n",
       "  'убрать': 916,\n",
       "  'плющий': 917,\n",
       "  'мохома': 918,\n",
       "  'блестеть': 919,\n",
       "  'белизна': 920,\n",
       "  'плечо': 921,\n",
       "  'глянец': 922,\n",
       "  'волос': 923,\n",
       "  'брильянт': 924,\n",
       "  'пройти': 925,\n",
       "  'расступиться': 926,\n",
       "  'прямо': 927,\n",
       "  'любезно': 928,\n",
       "  'любоваться': 929,\n",
       "  'стан': 930,\n",
       "  'открытый': 931,\n",
       "  'спина': 932,\n",
       "  'вносить': 933,\n",
       "  'блеск': 934,\n",
       "  'бал': 935,\n",
       "  'заметно': 936,\n",
       "  'тень': 937,\n",
       "  'кокетство': 938,\n",
       "  'совестно': 939,\n",
       "  'несомненный': 940,\n",
       "  'сильно': 941,\n",
       "  'победительно-действовать': 942,\n",
       "  'умалить': 943,\n",
       "  'поразить': 944,\n",
       "  'необычайный': 945,\n",
       "  'пожать': 946,\n",
       "  'опустить': 947,\n",
       "  'усаживаться': 948,\n",
       "  'перед': 949,\n",
       "  'освещать': 950,\n",
       "  'неизменный': 951,\n",
       "  'наклонять': 952,\n",
       "  'облокотить': 953,\n",
       "  'столик': 954,\n",
       "  'найти': 955,\n",
       "  'что-либо': 956,\n",
       "  'посматривать': 957,\n",
       "  'изредка': 958,\n",
       "  'давление': 959,\n",
       "  'изменить': 960,\n",
       "  'форма': 961,\n",
       "  'поправлять': 962,\n",
       "  'брильянтовый': 963,\n",
       "  'ожерелие': 964,\n",
       "  'складка': 965,\n",
       "  'производить': 966,\n",
       "  'впечатление': 967,\n",
       "  'оглядываться': 968,\n",
       "  'принимать': 969,\n",
       "  'вслед': 970,\n",
       "  'перейти': 971,\n",
       "  'чайный': 972,\n",
       "  'произвести': 973,\n",
       "  'перестановка': 974,\n",
       "  'оправиться': 975,\n",
       "  'хорошо': 976,\n",
       "  'приговаривать': 977,\n",
       "  'попросить': 978,\n",
       "  'начинать': 979,\n",
       "  'приняться': 980,\n",
       "  'перенести': 981,\n",
       "  'близко': 982,\n",
       "  'придвинуть': 983,\n",
       "  'сесть': 984,\n",
       "  'подле': 985,\n",
       "  'поражать': 986,\n",
       "  'необыкновенный': 987,\n",
       "  'сходство': 988,\n",
       "  'сестра-красавица': 989,\n",
       "  'поразительно': 990,\n",
       "  'дурной': 991,\n",
       "  'сестра': 992,\n",
       "  'освещаться': 993,\n",
       "  'жизнерадостный': 994,\n",
       "  'самодовольный': 995,\n",
       "  'молодая': 996,\n",
       "  'античный': 997,\n",
       "  'тело': 998,\n",
       "  'отуманить': 999,\n",
       "  ...}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster3.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим объекту несколько новых полей и функций и посмотрим как изменится список (при помощи оператора -)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "attr name =  C\n",
      "in print None\n",
      "---\n",
      "attr name =  C\n",
      "in print None\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.B = 0\n",
    "        \n",
    "    def __getattribute__(self, name):\n",
    "        print(\"attr name = \", name)\n",
    "        #if name not in self.__dict__.keys():\n",
    "        #    return None\n",
    "        #return self.__dict__[name]\n",
    "        \n",
    "\n",
    "print('---')\n",
    "a = A()\n",
    "print('---')\n",
    "b = A()\n",
    "print('---')\n",
    "b.C = 'asd'\n",
    "print('---')\n",
    "print(\"in print\", b.C)\n",
    "print('---')\n",
    "print(\"in print\", a.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster5 = FasterMorphology2()\n",
    "faster4 = FasterMorphology2()\n",
    "faster4.dummy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dummy'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dir(faster4))-set(dir(faster5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметьте, добавить поля к встроенным типам не получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdasdasdas\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dummy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52011/76320232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwww\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'asdasdasdas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'eeeee'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dummy'"
     ]
    }
   ],
   "source": [
    "www = str('asdasdasdas')\n",
    "print(www)\n",
    "www.dummy = 'eeeee'\n",
    "print(www.dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, нам вдруг захотелось, чтобы faster4 начал считать Евклидово расстояние. Для этого добавим в объект соответствующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideDistance(self, a, b):\n",
    "    \"\"\"sdfrweq weqr wq\"\"\"\n",
    "    return math.sqrt(sum([aa * bb for aa, bb in zip(a, b)]))\n",
    "\n",
    "faster4.EuclidianSimilarity = EuclideDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EuclideDistance() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52011/614473266.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfaster4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEuclidianSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: EuclideDistance() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": [
    "faster4.EuclidianSimilarity([1,2,3], [3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то опять пошло не так. Оказывается в Питоне функции отличаются от методов класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method FasterMorphology2.analyzeWords of <__main__.FasterMorphology2 object at 0x7f95d1f0ea90>>\n",
      "<function EuclideDistance at 0x7f95cb237e50>\n"
     ]
    }
   ],
   "source": [
    "print(faster4.analyzeWords)\n",
    "print(faster4.EuclidianSimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы привязать метод к отдельному объекту необходимо вызвать специальную функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster4.EuclidianSimilarity = types.MethodType(EuclideDistance, faster4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот поменять класс целиком довольно просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "class forTests:\n",
    "    aaaa = 4\n",
    "    def __init__(self):\n",
    "        self.aha = 0\n",
    "        self.uhu = 1\n",
    "\n",
    "test1 = forTests()\n",
    "#dir(test1)\n",
    "\n",
    "def dummyFunc(self):\n",
    "    return 0\n",
    "\n",
    "forTests.dummy = dummyFunc\n",
    "\n",
    "test2 = forTests()\n",
    "\n",
    "print(set(dir(test1)) - set(dir(test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но обратите внимание, метод появился теперь у всех объектов данного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.aaaa = 5\n",
    "test1.aaaa, test2.aaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"nice\":2, \"table\":5, \"the\":23}>\n",
    "{\"nice\":15, \"the\":15, >\"pretty\":5}\n",
    "\n",
    "[00000000000500000000000230000000002]\n",
    "[000000000000000005000001500000000015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
